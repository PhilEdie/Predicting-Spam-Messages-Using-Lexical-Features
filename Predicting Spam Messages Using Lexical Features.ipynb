{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "pmpByatncf-B",
        "jiu9DD1x_N0x",
        "hW52vACK92Oi",
        "zl4uOYhmy_Go"
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Phil Edie\n",
        "\n",
        "## Student ID: 300406035\n",
        "\n",
        "## Identifying Spam Text Messages Using Lexical Features\n",
        "\n"
      ],
      "metadata": {
        "id": "pHXhN--bvTSe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Introduction and Research Question(s):\n",
        "\n"
      ],
      "metadata": {
        "id": "pmpByatncf-B"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Spam text messages are becoming increasingly more prevalent as phone numbers become older and are more frequently reused.  Email services such as Gmail have included spam filters as a part of their service. However, many mobile providers don’t include this feature.  Introducing a spam filter has several privacy concerns. A spam filter based on the message contents would require the mobile provider to be able to read the contents of the message. An alternative approach would be to make predictions solely based on the linguistic features of the message. This would help to preserve some level of privacy for mobile users. \n",
        "The research question explored in this project is: \n",
        "Can spam text messages be easily identified using linguistic features?\n",
        "To answer this question, I will be comparing the following features between spam and non-spam (Ham) messages to understand if any patterns exist:\n",
        "\n",
        "-\tAverage Word Count\n",
        "-\tPercentage of words with typos\n",
        "-\tAverage sentiment\n",
        "-\tAverage lexical diversity\n",
        "-\tFrequency Distribution\n",
        "\n",
        "I will then train a classification machine learning model that predicts whether a text message is spam based solely on these features, and then compare the results to a model trained directly on the text itself.\n",
        "If the prediction accuracy is comparable, then our approach to spam filtering would be a feasible solution. \n"
      ],
      "metadata": {
        "id": "PJBoC3PfcmxE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Data and Description of Data:"
      ],
      "metadata": {
        "id": "0QNDb7RQg-JU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I will be using UCI’s SMS Spam Collection Data Set from the UCI machine learning repository. I chose this dataset as it is one of the only publicly available datasets specific to text messages. More information can be found here: https://archive.ics.uci.edu/ml/datasets/SMS+Spam+Collection\n",
        "UCI also provides this dataset in a CSV format through Kaggle. This is the version of the dataset I used for this project, as it is easier to parse: https://www.kaggle.com/datasets/uciml/sms-spam-collection-dataset\n",
        "This dataset contains two columns. One column is the classification (“Spam” or “Ham”) and the other is the text message content. I will be referring to non-spam messages as Ham to keep comparisons concise. The dataset contains 5572 rows. 747 messages are spam, and 4825 messages are ham. \n"
      ],
      "metadata": {
        "id": "rAcxVcr_hBkV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. Explanation of the Program:"
      ],
      "metadata": {
        "id": "eT8YhR8VlOll"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Loading Data and Data Cleaning\n",
        "\n",
        "I complete the following steps:\n",
        "1.\tI start by reading the CSV file and storing it as a Pandas DataFrame. This allows us to easily read the data and make fast computations on the dataset. We can apply operations to each row of the DataFrame using the DataFrame function assign().\n",
        "2.\tI then drop blank columns and rename the remaining columns “IsSpam” and “Text”.\n",
        "3.\tValues “ham” and “spam” are mapped to Boolean values, for easier processing.\n",
        "4.\tI then ensure that our dataset contains no null values. \n",
        "5.\tAll non-Ascii characters are removed, as these aren’t compatible with NTLK.\n",
        "6.\tAll characters are set to lowercase. This is important later on when we calculate frequency distributions, as this calculation is case-sensitive.\n"
      ],
      "metadata": {
        "id": "ZEx34afFlUCD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data Analysis\n",
        "\n",
        "Here I complete the following steps:\n",
        "1.\tI add a word count column to the table. I manually remove punctuation, then use NTLK’s word_tokenize function to get the word counts for each row. \n",
        "\n",
        "2.\tI then add a typo count column to the table. I loop through each token of the text and assume that a word contains a typo when the word is not within the NTLK WordNet, or in the NTLK English stopwords set.\n",
        "\n",
        "3.\tI then add a sentiment column to the table. The sentiment is calculated using the NTLK Vader SentimentIntensityAnalyser. The sentiment is based on the compound score returned by the polarity_scores() function. \n",
        "\n",
        "4.\tI then add a lexical diversity column. The lexical diversity is calculated by dividing the total unique tokens by the total amount of tokens. \n",
        "\n",
        "5.\tFinally, I calculate the frequency distribution. I first divide the data into spam and ham sets. For both sets, I do the following:\n",
        "\n",
        "  * Combine all texts into a list of texts.\n",
        "  * Divide each text up into a list of tokens using NTLK’s word_tokenize()\n",
        "  * Remove all stopwords from the list of tokens\n",
        "  * Append the list of tokens to a final list\n",
        "  * Pass the final list into NTLK’s FreqDist() function, to get a final frequency distribution.\n",
        "\n",
        "  Using this information, I can manually compare the top 10 most common words between the spam and ham sets.\n"
      ],
      "metadata": {
        "id": "GTklZclglg3-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Machine Learning"
      ],
      "metadata": {
        "id": "SxKzotZSl9Qe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I use different sets of models and features to determine which combination provides the most accurate predictions.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "potrD2kymF5i"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Feature set 1: X = [Text], Y = [IsSpam]\n",
        "\n",
        "This provides our baseline accuracy. The models are trained directly on the text itself. We would expect Feature Set 1 to have the highest average accuracy score. "
      ],
      "metadata": {
        "id": "5LuFdJHOmuiC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Feature set 2: X = [Text, WordCount, TypoCount, Sentiment, LexicalDiversity], Y = [IsSpam]\n",
        "\n",
        "Feature set 2 aims to test whether including our linguistic features alongside our text improves the average accuracy score."
      ],
      "metadata": {
        "id": "B7DI1uMWmztP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Feature set 3: X = [Text, WordCount, TypoCount, Sentiment], Y = [IsSpam]\n",
        "\n",
        "Since Lexical Diversity isn’t significantly different between spam and ham, I repeated feature set 2 with lexical diversity excluded."
      ],
      "metadata": {
        "id": "rM-PmGoMm8hR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Feature set 4: X = [WordCount, TypoCount, Sentiment, LexicalDiversity], Y = [IsSpam]\n",
        "\n",
        "Feature set 4 tests how accurate our model can be when trained purely on lexical features. "
      ],
      "metadata": {
        "id": "RD7g_kxwm_rN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Feature set 5: X = [WordCount, TypoCount, Sentiment], Y = [IsSpam]\n",
        "\n",
        "This feature set 5 repeats feature set 4 without  LexicalDiversity."
      ],
      "metadata": {
        "id": "VTFXxDWknDQJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "For each feature set, I trained and tested on the following four models, using default parameters:\n",
        "\n",
        "SVC, Gaussian Naiive Bays, Decision Tree Classifier, K-Neighbours Classifier.\n",
        "\n",
        "\n",
        "I used the following process for each model:\n",
        "\n",
        "1.\tSplit the model into train and test sets, with 90% of the data used for training. The data is randomly shuffled, with indexes reset.\n",
        "\n",
        "2.\tIf the data contains the text column, we will encode the text data using SK-Learn’s TfidfVectorizer().\n",
        "\n",
        "3.\tFit the model using the training data.\n",
        "\n",
        "4.\tApply the same encoding to the text data in the test set, if the text column exists.\n",
        "\n",
        "5.\tMake predictions, and calculate an overall accuracy score.\n",
        "\n",
        "6.\tSave the accuracy scores for a final summary.\n"
      ],
      "metadata": {
        "id": "31r-JBQtnJ07"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4. Python Program:"
      ],
      "metadata": {
        "id": "qSpGhsw4nbOH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Imports"
      ],
      "metadata": {
        "id": "kE5aN71pjKIJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import string\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from nltk.corpus import stopwords\n",
        "import nltk, re\n",
        "import pandas as pd\n",
        "import nltk, re\n",
        "import nltk\n",
        "from nltk.corpus import wordnet as WN\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "nltk.download('wordnet')\n",
        "nltk.download('omw-1.4')\n",
        "nltk.download(['stopwords', 'punkt'])\n",
        "\n",
        "stop_words_en = set(stopwords.words('english'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7lbdgWH9wu_b",
        "outputId": "b9ddcdb7-d95f-4b34-823b-184027afa937"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load Dataset"
      ],
      "metadata": {
        "id": "jiu9DD1x_N0x"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I start by reading the CSV file and storing it as a Pandas DataFrame. This allows us to easily read the data and make fast computations on the dataset. We can apply operations to each row of the DataFrame using the DataFrame function assign().\n",
        "\n",
        "To load the dataset locally, use the below with the correct file path.\n",
        "\n",
        "`df = pd.read_csv('<PATH_TO_FOLDER_CONTAINING_IPYNB>/spam.csv', encoding_errors= 'replace')`"
      ],
      "metadata": {
        "id": "EraIuEURgQOD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "df = pd.read_csv('drive/My Drive/LING226/spam.csv', encoding_errors= 'replace')\n",
        "\n",
        "# df = pd.read_csv('<PATH_TO_FOLDER_CONTAINING_IPYNB>/spam.csv', encoding_errors= 'replace')\n",
        "\n",
        "display(df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 400
        },
        "id": "OaJ9qB0ixLb6",
        "outputId": "111e1651-7afc-45a6-d703-f54f9ad19aef"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "        v1                                                 v2 Unnamed: 2  \\\n",
              "0      ham  Go until jurong point, crazy.. Available only ...        NaN   \n",
              "1      ham                      Ok lar... Joking wif u oni...        NaN   \n",
              "2     spam  Free entry in 2 a wkly comp to win FA Cup fina...        NaN   \n",
              "3      ham  U dun say so early hor... U c already then say...        NaN   \n",
              "4      ham  Nah I don't think he goes to usf, he lives aro...        NaN   \n",
              "...    ...                                                ...        ...   \n",
              "5567  spam  This is the 2nd time we have tried 2 contact u...        NaN   \n",
              "5568   ham              Will �_ b going to esplanade fr home?        NaN   \n",
              "5569   ham  Pity, * was in mood for that. So...any other s...        NaN   \n",
              "5570   ham  The guy did some bitching but I acted like i'd...        NaN   \n",
              "5571   ham                         Rofl. Its true to its name        NaN   \n",
              "\n",
              "     Unnamed: 3 Unnamed: 4  \n",
              "0           NaN        NaN  \n",
              "1           NaN        NaN  \n",
              "2           NaN        NaN  \n",
              "3           NaN        NaN  \n",
              "4           NaN        NaN  \n",
              "...         ...        ...  \n",
              "5567        NaN        NaN  \n",
              "5568        NaN        NaN  \n",
              "5569        NaN        NaN  \n",
              "5570        NaN        NaN  \n",
              "5571        NaN        NaN  \n",
              "\n",
              "[5572 rows x 5 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d3d605d4-f8ed-4b7c-86b9-fc7bd7517011\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>v1</th>\n",
              "      <th>v2</th>\n",
              "      <th>Unnamed: 2</th>\n",
              "      <th>Unnamed: 3</th>\n",
              "      <th>Unnamed: 4</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ham</td>\n",
              "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ham</td>\n",
              "      <td>Ok lar... Joking wif u oni...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>spam</td>\n",
              "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ham</td>\n",
              "      <td>U dun say so early hor... U c already then say...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ham</td>\n",
              "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5567</th>\n",
              "      <td>spam</td>\n",
              "      <td>This is the 2nd time we have tried 2 contact u...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5568</th>\n",
              "      <td>ham</td>\n",
              "      <td>Will �_ b going to esplanade fr home?</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5569</th>\n",
              "      <td>ham</td>\n",
              "      <td>Pity, * was in mood for that. So...any other s...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5570</th>\n",
              "      <td>ham</td>\n",
              "      <td>The guy did some bitching but I acted like i'd...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5571</th>\n",
              "      <td>ham</td>\n",
              "      <td>Rofl. Its true to its name</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5572 rows × 5 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d3d605d4-f8ed-4b7c-86b9-fc7bd7517011')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-d3d605d4-f8ed-4b7c-86b9-fc7bd7517011 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-d3d605d4-f8ed-4b7c-86b9-fc7bd7517011');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Cleaning"
      ],
      "metadata": {
        "id": "hW52vACK92Oi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Drop Empty Columns, and rename the remaining columns “IsSpam” and “Text”."
      ],
      "metadata": {
        "id": "VNTNpLZP1AAh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.drop(df.columns[[2,3,4]], axis=1, inplace=True)\n",
        "df.columns = ['IsSpam', 'Text']\n",
        "display(df)"
      ],
      "metadata": {
        "id": "YbSAnC_n1E40",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 384
        },
        "outputId": "5bcc8ec2-3199-419f-8a9c-b1cf0a85ce06"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "     IsSpam                                               Text\n",
              "0       ham  Go until jurong point, crazy.. Available only ...\n",
              "1       ham                      Ok lar... Joking wif u oni...\n",
              "2      spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
              "3       ham  U dun say so early hor... U c already then say...\n",
              "4       ham  Nah I don't think he goes to usf, he lives aro...\n",
              "...     ...                                                ...\n",
              "5567   spam  This is the 2nd time we have tried 2 contact u...\n",
              "5568    ham              Will �_ b going to esplanade fr home?\n",
              "5569    ham  Pity, * was in mood for that. So...any other s...\n",
              "5570    ham  The guy did some bitching but I acted like i'd...\n",
              "5571    ham                         Rofl. Its true to its name\n",
              "\n",
              "[5572 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-0cbe37e3-33c6-4a6e-b7d6-cd3c2ecfab48\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>IsSpam</th>\n",
              "      <th>Text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ham</td>\n",
              "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ham</td>\n",
              "      <td>Ok lar... Joking wif u oni...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>spam</td>\n",
              "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ham</td>\n",
              "      <td>U dun say so early hor... U c already then say...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ham</td>\n",
              "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5567</th>\n",
              "      <td>spam</td>\n",
              "      <td>This is the 2nd time we have tried 2 contact u...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5568</th>\n",
              "      <td>ham</td>\n",
              "      <td>Will �_ b going to esplanade fr home?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5569</th>\n",
              "      <td>ham</td>\n",
              "      <td>Pity, * was in mood for that. So...any other s...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5570</th>\n",
              "      <td>ham</td>\n",
              "      <td>The guy did some bitching but I acted like i'd...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5571</th>\n",
              "      <td>ham</td>\n",
              "      <td>Rofl. Its true to its name</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5572 rows × 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0cbe37e3-33c6-4a6e-b7d6-cd3c2ecfab48')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-0cbe37e3-33c6-4a6e-b7d6-cd3c2ecfab48 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-0cbe37e3-33c6-4a6e-b7d6-cd3c2ecfab48');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Drop any rows with null values."
      ],
      "metadata": {
        "id": "9bFgu5K296SB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print('Shape before: ' , df.shape)\n",
        "df = df.dropna(how='any',axis=0)\n",
        "print('Shape after: ' , df.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dUvmNTAK9A0X",
        "outputId": "5ef31e83-2f57-4cb4-9873-d9e7d622411f"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape before:  (5572, 2)\n",
            "Shape after:  (5572, 2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Drop any rows with blank values."
      ],
      "metadata": {
        "id": "MRceKBTPzMSD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print('Shape before: ' , df.shape)\n",
        "df = df[df['Text'].astype(bool)]                                                                                                                  \n",
        "print('Shape after: ' , df.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QDyFrt2FzLSM",
        "outputId": "ad623c86-74d8-4e80-cb9a-5283495f8c46"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape before:  (5572, 2)\n",
            "Shape after:  (5572, 2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Convert 'Ham' and 'Spam' to boolean values."
      ],
      "metadata": {
        "id": "n5oiTEsB-mhs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "d = {'ham': 0,'spam':1}\n",
        "df['IsSpam']=df['IsSpam'].map(d)\n",
        "df['IsSpam']=df['IsSpam'].astype('bool')\n",
        "display(df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 384
        },
        "id": "95e5_iCz-tWQ",
        "outputId": "b9a6894e-0703-4293-98b2-eef2f64e5cd4"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "      IsSpam                                               Text\n",
              "0      False  Go until jurong point, crazy.. Available only ...\n",
              "1      False                      Ok lar... Joking wif u oni...\n",
              "2       True  Free entry in 2 a wkly comp to win FA Cup fina...\n",
              "3      False  U dun say so early hor... U c already then say...\n",
              "4      False  Nah I don't think he goes to usf, he lives aro...\n",
              "...      ...                                                ...\n",
              "5567    True  This is the 2nd time we have tried 2 contact u...\n",
              "5568   False              Will �_ b going to esplanade fr home?\n",
              "5569   False  Pity, * was in mood for that. So...any other s...\n",
              "5570   False  The guy did some bitching but I acted like i'd...\n",
              "5571   False                         Rofl. Its true to its name\n",
              "\n",
              "[5572 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e0c4b917-3243-4d48-93c7-9bdb235731a8\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>IsSpam</th>\n",
              "      <th>Text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>False</td>\n",
              "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>False</td>\n",
              "      <td>Ok lar... Joking wif u oni...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>True</td>\n",
              "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>False</td>\n",
              "      <td>U dun say so early hor... U c already then say...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>False</td>\n",
              "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5567</th>\n",
              "      <td>True</td>\n",
              "      <td>This is the 2nd time we have tried 2 contact u...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5568</th>\n",
              "      <td>False</td>\n",
              "      <td>Will �_ b going to esplanade fr home?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5569</th>\n",
              "      <td>False</td>\n",
              "      <td>Pity, * was in mood for that. So...any other s...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5570</th>\n",
              "      <td>False</td>\n",
              "      <td>The guy did some bitching but I acted like i'd...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5571</th>\n",
              "      <td>False</td>\n",
              "      <td>Rofl. Its true to its name</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5572 rows × 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e0c4b917-3243-4d48-93c7-9bdb235731a8')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-e0c4b917-3243-4d48-93c7-9bdb235731a8 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-e0c4b917-3243-4d48-93c7-9bdb235731a8');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Remove non Ascii characters."
      ],
      "metadata": {
        "id": "bnv1MokqAMvH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "All non-Ascii characters are removed, as these aren’t compatible with NTLK."
      ],
      "metadata": {
        "id": "8_2z533pjwQH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df['Text'] = df['Text'].str.encode('ascii', 'ignore').str.decode('ascii')\n",
        "display(df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 384
        },
        "id": "PeK9P0NfAEOb",
        "outputId": "30f21cb5-84a1-4674-c36b-3754b5e72d93"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "      IsSpam                                               Text\n",
              "0      False  Go until jurong point, crazy.. Available only ...\n",
              "1      False                      Ok lar... Joking wif u oni...\n",
              "2       True  Free entry in 2 a wkly comp to win FA Cup fina...\n",
              "3      False  U dun say so early hor... U c already then say...\n",
              "4      False  Nah I don't think he goes to usf, he lives aro...\n",
              "...      ...                                                ...\n",
              "5567    True  This is the 2nd time we have tried 2 contact u...\n",
              "5568   False               Will _ b going to esplanade fr home?\n",
              "5569   False  Pity, * was in mood for that. So...any other s...\n",
              "5570   False  The guy did some bitching but I acted like i'd...\n",
              "5571   False                         Rofl. Its true to its name\n",
              "\n",
              "[5572 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-002664c5-dc00-4b20-a7c0-a31c50849a3f\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>IsSpam</th>\n",
              "      <th>Text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>False</td>\n",
              "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>False</td>\n",
              "      <td>Ok lar... Joking wif u oni...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>True</td>\n",
              "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>False</td>\n",
              "      <td>U dun say so early hor... U c already then say...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>False</td>\n",
              "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5567</th>\n",
              "      <td>True</td>\n",
              "      <td>This is the 2nd time we have tried 2 contact u...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5568</th>\n",
              "      <td>False</td>\n",
              "      <td>Will _ b going to esplanade fr home?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5569</th>\n",
              "      <td>False</td>\n",
              "      <td>Pity, * was in mood for that. So...any other s...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5570</th>\n",
              "      <td>False</td>\n",
              "      <td>The guy did some bitching but I acted like i'd...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5571</th>\n",
              "      <td>False</td>\n",
              "      <td>Rofl. Its true to its name</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5572 rows × 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-002664c5-dc00-4b20-a7c0-a31c50849a3f')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-002664c5-dc00-4b20-a7c0-a31c50849a3f button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-002664c5-dc00-4b20-a7c0-a31c50849a3f');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Set all Text values to lowercase."
      ],
      "metadata": {
        "id": "U0GeOL0SkL6p"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This is important later on when we calculate frequency distributions, as this calculation is case-sensitive."
      ],
      "metadata": {
        "id": "Xi8hmdZfj05E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df['Text'] = df['Text'].str.lower()\n",
        "display(df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 384
        },
        "id": "V2-f24s_kLaL",
        "outputId": "2c76ee08-0e3b-49f6-d092-af2da72bf57c"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "      IsSpam                                               Text\n",
              "0      False  go until jurong point, crazy.. available only ...\n",
              "1      False                      ok lar... joking wif u oni...\n",
              "2       True  free entry in 2 a wkly comp to win fa cup fina...\n",
              "3      False  u dun say so early hor... u c already then say...\n",
              "4      False  nah i don't think he goes to usf, he lives aro...\n",
              "...      ...                                                ...\n",
              "5567    True  this is the 2nd time we have tried 2 contact u...\n",
              "5568   False               will _ b going to esplanade fr home?\n",
              "5569   False  pity, * was in mood for that. so...any other s...\n",
              "5570   False  the guy did some bitching but i acted like i'd...\n",
              "5571   False                         rofl. its true to its name\n",
              "\n",
              "[5572 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b0438898-6fa2-4b76-b5e0-badeaa49f26d\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>IsSpam</th>\n",
              "      <th>Text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>False</td>\n",
              "      <td>go until jurong point, crazy.. available only ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>False</td>\n",
              "      <td>ok lar... joking wif u oni...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>True</td>\n",
              "      <td>free entry in 2 a wkly comp to win fa cup fina...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>False</td>\n",
              "      <td>u dun say so early hor... u c already then say...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>False</td>\n",
              "      <td>nah i don't think he goes to usf, he lives aro...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5567</th>\n",
              "      <td>True</td>\n",
              "      <td>this is the 2nd time we have tried 2 contact u...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5568</th>\n",
              "      <td>False</td>\n",
              "      <td>will _ b going to esplanade fr home?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5569</th>\n",
              "      <td>False</td>\n",
              "      <td>pity, * was in mood for that. so...any other s...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5570</th>\n",
              "      <td>False</td>\n",
              "      <td>the guy did some bitching but i acted like i'd...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5571</th>\n",
              "      <td>False</td>\n",
              "      <td>rofl. its true to its name</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5572 rows × 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b0438898-6fa2-4b76-b5e0-badeaa49f26d')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-b0438898-6fa2-4b76-b5e0-badeaa49f26d button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-b0438898-6fa2-4b76-b5e0-badeaa49f26d');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Distribution of Spam vs Non Spam"
      ],
      "metadata": {
        "id": "1SyuHJKHUXeW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can see an uneven distribution of spam and ham texts in the dataset."
      ],
      "metadata": {
        "id": "mxLGt9dnj4Ng"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plot = df.IsSpam.value_counts().plot(kind='bar', title='Distribution of Non-Spam (False) vs Spam (True)')\n",
        "print(df.IsSpam.value_counts())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 344
        },
        "id": "YnpRHPPtTyLk",
        "outputId": "78b05bfb-520d-4dc2-fb6c-bcb7b5b18caa"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "False    4825\n",
            "True      747\n",
            "Name: IsSpam, dtype: int64\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Analysis"
      ],
      "metadata": {
        "id": "zl4uOYhmy_Go"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Add word count column"
      ],
      "metadata": {
        "id": "ZX5LBVzF7_3V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_tokens(line):\n",
        "    \"\"\" Takes a string, removes any punctuation, then returns a list of tokens. \"\"\"\n",
        "    line = remove_punct(line)\n",
        "    return nltk.word_tokenize(line)\n",
        "\n",
        "def remove_punct(text):\n",
        "  # Remove punctuation\n",
        "  for character in string.punctuation: # contains this punctuation: !\"#$%&'()*+, -./:;<=>?@[\\]^_`{|}~\n",
        "    text = text.replace(character, '')\n",
        "  return text"
      ],
      "metadata": {
        "id": "2v3MS7_YOhaH"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.assign(WordCount=df['Text'].apply(lambda x: len(get_tokens(x))))\n",
        "display(df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 384
        },
        "id": "w1HQFXqh8NlE",
        "outputId": "79a86203-88e3-4fd6-c7f3-963ead511d04"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "      IsSpam                                               Text  WordCount\n",
              "0      False  go until jurong point, crazy.. available only ...         20\n",
              "1      False                      ok lar... joking wif u oni...          6\n",
              "2       True  free entry in 2 a wkly comp to win fa cup fina...         28\n",
              "3      False  u dun say so early hor... u c already then say...         11\n",
              "4      False  nah i don't think he goes to usf, he lives aro...         13\n",
              "...      ...                                                ...        ...\n",
              "5567    True  this is the 2nd time we have tried 2 contact u...         30\n",
              "5568   False               will _ b going to esplanade fr home?          7\n",
              "5569   False  pity, * was in mood for that. so...any other s...          9\n",
              "5570   False  the guy did some bitching but i acted like i'd...         26\n",
              "5571   False                         rofl. its true to its name          6\n",
              "\n",
              "[5572 rows x 3 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-faf3153c-0675-4158-b9c9-d0e22ef09d47\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>IsSpam</th>\n",
              "      <th>Text</th>\n",
              "      <th>WordCount</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>False</td>\n",
              "      <td>go until jurong point, crazy.. available only ...</td>\n",
              "      <td>20</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>False</td>\n",
              "      <td>ok lar... joking wif u oni...</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>True</td>\n",
              "      <td>free entry in 2 a wkly comp to win fa cup fina...</td>\n",
              "      <td>28</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>False</td>\n",
              "      <td>u dun say so early hor... u c already then say...</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>False</td>\n",
              "      <td>nah i don't think he goes to usf, he lives aro...</td>\n",
              "      <td>13</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5567</th>\n",
              "      <td>True</td>\n",
              "      <td>this is the 2nd time we have tried 2 contact u...</td>\n",
              "      <td>30</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5568</th>\n",
              "      <td>False</td>\n",
              "      <td>will _ b going to esplanade fr home?</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5569</th>\n",
              "      <td>False</td>\n",
              "      <td>pity, * was in mood for that. so...any other s...</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5570</th>\n",
              "      <td>False</td>\n",
              "      <td>the guy did some bitching but i acted like i'd...</td>\n",
              "      <td>26</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5571</th>\n",
              "      <td>False</td>\n",
              "      <td>rofl. its true to its name</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5572 rows × 3 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-faf3153c-0675-4158-b9c9-d0e22ef09d47')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-faf3153c-0675-4158-b9c9-d0e22ef09d47 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-faf3153c-0675-4158-b9c9-d0e22ef09d47');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Compare typo ratios between Spam and Ham"
      ],
      "metadata": {
        "id": "Q9ZKK0VSNVDO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Functions"
      ],
      "metadata": {
        "id": "WhFsaDB5A_kn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Help from https://stackoverflow.com/questions/40188226/nltks-spell-checker-is-not-working-correctly\n",
        "\n",
        "def line_spelling_error_count(line):\n",
        "  count = 0\n",
        "  for i in get_tokens(line):\n",
        "      if not WN.synsets(i) and i not in stop_words_en:\n",
        "        count += 1\n",
        "  return count"
      ],
      "metadata": {
        "id": "wYE8UiViBK2q"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.assign(TypoCount=df['Text'].apply(line_spelling_error_count))\n",
        "display(df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 384
        },
        "id": "BL3dlZDzA9dH",
        "outputId": "74578501-5b3f-4de2-c255-526c48bf88e0"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "      IsSpam                                               Text  WordCount  \\\n",
              "0      False  go until jurong point, crazy.. available only ...         20   \n",
              "1      False                      ok lar... joking wif u oni...          6   \n",
              "2       True  free entry in 2 a wkly comp to win fa cup fina...         28   \n",
              "3      False  u dun say so early hor... u c already then say...         11   \n",
              "4      False  nah i don't think he goes to usf, he lives aro...         13   \n",
              "...      ...                                                ...        ...   \n",
              "5567    True  this is the 2nd time we have tried 2 contact u...         30   \n",
              "5568   False               will _ b going to esplanade fr home?          7   \n",
              "5569   False  pity, * was in mood for that. so...any other s...          9   \n",
              "5570   False  the guy did some bitching but i acted like i'd...         26   \n",
              "5571   False                         rofl. its true to its name          6   \n",
              "\n",
              "      TypoCount  \n",
              "0             5  \n",
              "1             2  \n",
              "2             8  \n",
              "3             1  \n",
              "4             3  \n",
              "...         ...  \n",
              "5567          6  \n",
              "5568          0  \n",
              "5569          1  \n",
              "5570          2  \n",
              "5571          1  \n",
              "\n",
              "[5572 rows x 4 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-7b76d56b-00f2-4abe-b87c-f623ff981bcc\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>IsSpam</th>\n",
              "      <th>Text</th>\n",
              "      <th>WordCount</th>\n",
              "      <th>TypoCount</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>False</td>\n",
              "      <td>go until jurong point, crazy.. available only ...</td>\n",
              "      <td>20</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>False</td>\n",
              "      <td>ok lar... joking wif u oni...</td>\n",
              "      <td>6</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>True</td>\n",
              "      <td>free entry in 2 a wkly comp to win fa cup fina...</td>\n",
              "      <td>28</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>False</td>\n",
              "      <td>u dun say so early hor... u c already then say...</td>\n",
              "      <td>11</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>False</td>\n",
              "      <td>nah i don't think he goes to usf, he lives aro...</td>\n",
              "      <td>13</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5567</th>\n",
              "      <td>True</td>\n",
              "      <td>this is the 2nd time we have tried 2 contact u...</td>\n",
              "      <td>30</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5568</th>\n",
              "      <td>False</td>\n",
              "      <td>will _ b going to esplanade fr home?</td>\n",
              "      <td>7</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5569</th>\n",
              "      <td>False</td>\n",
              "      <td>pity, * was in mood for that. so...any other s...</td>\n",
              "      <td>9</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5570</th>\n",
              "      <td>False</td>\n",
              "      <td>the guy did some bitching but i acted like i'd...</td>\n",
              "      <td>26</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5571</th>\n",
              "      <td>False</td>\n",
              "      <td>rofl. its true to its name</td>\n",
              "      <td>6</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5572 rows × 4 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7b76d56b-00f2-4abe-b87c-f623ff981bcc')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-7b76d56b-00f2-4abe-b87c-f623ff981bcc button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-7b76d56b-00f2-4abe-b87c-f623ff981bcc');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Sentiment Analysis"
      ],
      "metadata": {
        "id": "wqb2kw4VRiZh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('vader_lexicon')\n",
        "\n",
        "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
        "sid = SentimentIntensityAnalyzer()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k_DmeLchNrRK",
        "outputId": "6f54b185-0462-4ba6-9e3e-1e05fff9b659"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package vader_lexicon to /root/nltk_data...\n",
            "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def sentiment_lookup(sentence):\n",
        "  sentiment = sid.polarity_scores(sentence)\n",
        "  return sentiment['compound']"
      ],
      "metadata": {
        "id": "SCMRyPuWR4KJ"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.assign(Sentiment=df['Text'].apply(sentiment_lookup))\n",
        "display(df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 384
        },
        "id": "X3sQa9onXxhQ",
        "outputId": "002987c8-5497-4441-8e2b-fa9bad9147ef"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "      IsSpam                                               Text  WordCount  \\\n",
              "0      False  go until jurong point, crazy.. available only ...         20   \n",
              "1      False                      ok lar... joking wif u oni...          6   \n",
              "2       True  free entry in 2 a wkly comp to win fa cup fina...         28   \n",
              "3      False  u dun say so early hor... u c already then say...         11   \n",
              "4      False  nah i don't think he goes to usf, he lives aro...         13   \n",
              "...      ...                                                ...        ...   \n",
              "5567    True  this is the 2nd time we have tried 2 contact u...         30   \n",
              "5568   False               will _ b going to esplanade fr home?          7   \n",
              "5569   False  pity, * was in mood for that. so...any other s...          9   \n",
              "5570   False  the guy did some bitching but i acted like i'd...         26   \n",
              "5571   False                         rofl. its true to its name          6   \n",
              "\n",
              "      TypoCount  Sentiment  \n",
              "0             5     0.6249  \n",
              "1             2     0.4767  \n",
              "2             8     0.7964  \n",
              "3             1     0.0000  \n",
              "4             3    -0.1027  \n",
              "...         ...        ...  \n",
              "5567          6     0.8805  \n",
              "5568          0     0.0000  \n",
              "5569          1    -0.2960  \n",
              "5570          2     0.8934  \n",
              "5571          1     0.7579  \n",
              "\n",
              "[5572 rows x 5 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f26c9e19-7864-4a6c-8bc2-8afdd9e91306\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>IsSpam</th>\n",
              "      <th>Text</th>\n",
              "      <th>WordCount</th>\n",
              "      <th>TypoCount</th>\n",
              "      <th>Sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>False</td>\n",
              "      <td>go until jurong point, crazy.. available only ...</td>\n",
              "      <td>20</td>\n",
              "      <td>5</td>\n",
              "      <td>0.6249</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>False</td>\n",
              "      <td>ok lar... joking wif u oni...</td>\n",
              "      <td>6</td>\n",
              "      <td>2</td>\n",
              "      <td>0.4767</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>True</td>\n",
              "      <td>free entry in 2 a wkly comp to win fa cup fina...</td>\n",
              "      <td>28</td>\n",
              "      <td>8</td>\n",
              "      <td>0.7964</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>False</td>\n",
              "      <td>u dun say so early hor... u c already then say...</td>\n",
              "      <td>11</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>False</td>\n",
              "      <td>nah i don't think he goes to usf, he lives aro...</td>\n",
              "      <td>13</td>\n",
              "      <td>3</td>\n",
              "      <td>-0.1027</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5567</th>\n",
              "      <td>True</td>\n",
              "      <td>this is the 2nd time we have tried 2 contact u...</td>\n",
              "      <td>30</td>\n",
              "      <td>6</td>\n",
              "      <td>0.8805</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5568</th>\n",
              "      <td>False</td>\n",
              "      <td>will _ b going to esplanade fr home?</td>\n",
              "      <td>7</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5569</th>\n",
              "      <td>False</td>\n",
              "      <td>pity, * was in mood for that. so...any other s...</td>\n",
              "      <td>9</td>\n",
              "      <td>1</td>\n",
              "      <td>-0.2960</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5570</th>\n",
              "      <td>False</td>\n",
              "      <td>the guy did some bitching but i acted like i'd...</td>\n",
              "      <td>26</td>\n",
              "      <td>2</td>\n",
              "      <td>0.8934</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5571</th>\n",
              "      <td>False</td>\n",
              "      <td>rofl. its true to its name</td>\n",
              "      <td>6</td>\n",
              "      <td>1</td>\n",
              "      <td>0.7579</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5572 rows × 5 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f26c9e19-7864-4a6c-8bc2-8afdd9e91306')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-f26c9e19-7864-4a6c-8bc2-8afdd9e91306 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-f26c9e19-7864-4a6c-8bc2-8afdd9e91306');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Lexical Diversity"
      ],
      "metadata": {
        "id": "IkSM9ECenLuQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def lexical_diversity(input):\n",
        "    tokens = get_tokens(input)\n",
        "    if(len(tokens)) == 0:\n",
        "      return 0\n",
        "      \n",
        "    lexical_diversity = len(set(tokens)) / len(tokens)\n",
        "    return lexical_diversity"
      ],
      "metadata": {
        "id": "KWYzr7TFcbob"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.assign(LexicalDiversity=df['Text'].apply(lexical_diversity))\n",
        "display(df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 384
        },
        "id": "3zfGdP07cTlL",
        "outputId": "a78a5e02-4eff-4cf2-95bb-a0c6571f4fe5"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "      IsSpam                                               Text  WordCount  \\\n",
              "0      False  go until jurong point, crazy.. available only ...         20   \n",
              "1      False                      ok lar... joking wif u oni...          6   \n",
              "2       True  free entry in 2 a wkly comp to win fa cup fina...         28   \n",
              "3      False  u dun say so early hor... u c already then say...         11   \n",
              "4      False  nah i don't think he goes to usf, he lives aro...         13   \n",
              "...      ...                                                ...        ...   \n",
              "5567    True  this is the 2nd time we have tried 2 contact u...         30   \n",
              "5568   False               will _ b going to esplanade fr home?          7   \n",
              "5569   False  pity, * was in mood for that. so...any other s...          9   \n",
              "5570   False  the guy did some bitching but i acted like i'd...         26   \n",
              "5571   False                         rofl. its true to its name          6   \n",
              "\n",
              "      TypoCount  Sentiment  LexicalDiversity  \n",
              "0             5     0.6249          1.000000  \n",
              "1             2     0.4767          1.000000  \n",
              "2             8     0.7964          0.857143  \n",
              "3             1     0.0000          0.818182  \n",
              "4             3    -0.1027          0.923077  \n",
              "...         ...        ...               ...  \n",
              "5567          6     0.8805          0.833333  \n",
              "5568          0     0.0000          1.000000  \n",
              "5569          1    -0.2960          1.000000  \n",
              "5570          2     0.8934          1.000000  \n",
              "5571          1     0.7579          0.833333  \n",
              "\n",
              "[5572 rows x 6 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-3cf54dcb-18f8-4feb-a96c-28e6f3115930\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>IsSpam</th>\n",
              "      <th>Text</th>\n",
              "      <th>WordCount</th>\n",
              "      <th>TypoCount</th>\n",
              "      <th>Sentiment</th>\n",
              "      <th>LexicalDiversity</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>False</td>\n",
              "      <td>go until jurong point, crazy.. available only ...</td>\n",
              "      <td>20</td>\n",
              "      <td>5</td>\n",
              "      <td>0.6249</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>False</td>\n",
              "      <td>ok lar... joking wif u oni...</td>\n",
              "      <td>6</td>\n",
              "      <td>2</td>\n",
              "      <td>0.4767</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>True</td>\n",
              "      <td>free entry in 2 a wkly comp to win fa cup fina...</td>\n",
              "      <td>28</td>\n",
              "      <td>8</td>\n",
              "      <td>0.7964</td>\n",
              "      <td>0.857143</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>False</td>\n",
              "      <td>u dun say so early hor... u c already then say...</td>\n",
              "      <td>11</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.818182</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>False</td>\n",
              "      <td>nah i don't think he goes to usf, he lives aro...</td>\n",
              "      <td>13</td>\n",
              "      <td>3</td>\n",
              "      <td>-0.1027</td>\n",
              "      <td>0.923077</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5567</th>\n",
              "      <td>True</td>\n",
              "      <td>this is the 2nd time we have tried 2 contact u...</td>\n",
              "      <td>30</td>\n",
              "      <td>6</td>\n",
              "      <td>0.8805</td>\n",
              "      <td>0.833333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5568</th>\n",
              "      <td>False</td>\n",
              "      <td>will _ b going to esplanade fr home?</td>\n",
              "      <td>7</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5569</th>\n",
              "      <td>False</td>\n",
              "      <td>pity, * was in mood for that. so...any other s...</td>\n",
              "      <td>9</td>\n",
              "      <td>1</td>\n",
              "      <td>-0.2960</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5570</th>\n",
              "      <td>False</td>\n",
              "      <td>the guy did some bitching but i acted like i'd...</td>\n",
              "      <td>26</td>\n",
              "      <td>2</td>\n",
              "      <td>0.8934</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5571</th>\n",
              "      <td>False</td>\n",
              "      <td>rofl. its true to its name</td>\n",
              "      <td>6</td>\n",
              "      <td>1</td>\n",
              "      <td>0.7579</td>\n",
              "      <td>0.833333</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5572 rows × 6 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3cf54dcb-18f8-4feb-a96c-28e6f3115930')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-3cf54dcb-18f8-4feb-a96c-28e6f3115930 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-3cf54dcb-18f8-4feb-a96c-28e6f3115930');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Frequency Distribution"
      ],
      "metadata": {
        "id": "UzE0jowim5Q0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import word_tokenize\n",
        "from nltk import FreqDist\n",
        "\n",
        "def find_frequency_dist(line_list):\n",
        "  all_tokens = []\n",
        "\n",
        "  for line in line_list:\n",
        "    tokens = get_tokens(line)\n",
        "    tokens_no_stopwords = [i for i in tokens if i not in stop_words_en]\n",
        "    all_tokens.extend(tokens_no_stopwords)\n",
        "  \n",
        "  return FreqDist(all_tokens)"
      ],
      "metadata": {
        "id": "NbFcLV0F41v7"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "spam_freq_dist = find_frequency_dist(df.loc[df['IsSpam'] == True, 'Text'].to_list())\n",
        "ham_freq_dist = find_frequency_dist(df.loc[df['IsSpam'] == False, 'Text'].to_list())\n",
        "\n",
        "print(\"Spam Frequency Distribution:\", spam_freq_dist.most_common(10))\n",
        "print(\"Ham Frequency Distribution:\", ham_freq_dist.most_common(10))\n",
        "print(\"Spam Hapaxes:\", spam_freq_dist.hapaxes())\n",
        "print(\"Ham Hapaxes:\", ham_freq_dist.hapaxes())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hX_eGeln-wz8",
        "outputId": "0e5507c4-3642-49aa-98a1-cfd604e562d9"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Spam Frequency Distribution: [('call', 347), ('free', 216), ('2', 173), ('txt', 150), ('u', 147), ('ur', 144), ('mobile', 123), ('text', 120), ('4', 119), ('claim', 113)]\n",
            "Ham Frequency Distribution: [('u', 972), ('im', 458), ('2', 305), ('get', 303), ('ltgt', 276), ('ok', 272), ('dont', 268), ('go', 247), ('got', 243), ('ur', 240)]\n",
            "Spam Hapaxes: ['tb', 'chgs', 'xxxmobilemovieclub', 'httpwap', 'xxxmobilemovieclubcomnqjkgighjjgcbl', 'macedonia', 'goalsteam', 'trywales', 'scotland', '4txt120', 'poboxox36504w45wq', '5month', 'confirm', '07732584351', 'rodger', 'burns', 'jersey', 'devils', 'detroit', 'red', 'wings', 'ice', 'hockey', 'incorrect', 'divorce', 'barbie', 'kens', 'stuff', '0871277810910pmin', '5903', '09064019788', 'box42wr29c', '7548', '4041', 'gravel', 'nt', 'youll', 'svc', '69988', 'havent', 'replied', 'female', 'annoncement', '07046744435', 'bootydelious', '32f', 'yes434', 'no434', 'wwwsmsacubootydelious', 'bangbabes', 'way', 'bangb', 'internetservice', 'menu', '09061701939', 's89', '30th', 'wwwareyouuniquecouk', 'career', 'flyng', 'aries', 'recdthirtyeight', 'really', 'naked', 'changed', 'club4mobilescom', '87070', 'club4', 'box1146', 'mk45', '2wt', 'pay', '3680offer', '28thfebtcs', 'rodds1', '21m', 'aberdeen', 'united', 'kingdom', 'httpimg', 'acwicmb3cktz8r74', 'hide', 'gossip', 'fit', 'funky', 'smart', '85222', 'nowtcs', 'winnersclub', '84', 'gbp150week', 'shag', 'dointerested', 'sextextukcom', 'xxuk', 'suzy', '69876', 'website', '08708800282', 'call2optoutf4q', 'rp176781', 'wwwregalportfoliocouk', '08717205546', 't91', 'gbp', '09057039994', '2814032', '3x150pw', '09064012103', '09111032124', 'pobox12n146tf150p', '09058094455', 'upgrdcentre', '9153', '26th', 'okmail', 'moan', '69888nyt', 'boltblue', 'poly3', 'slide', 'yeah', 'slow', 'jamz', 'toxic', '8', 'topped', 'httpwwwbubbletextcom', 'renewal', 'pin', 'tgxxrz', '08718729755', 'recieve', 'channel', 'teletext', 'pg', '07815296484', '41782', '181104', 'wwwapplausestorecom', 'monthlysubscription50pmsg', 'max6month', 'tcsc', '2stop', '09050005321', 'textand', '08002988890', '07753741225', '08715203677', '42478', '241004', 'xclusiveclubsaisai', '2morow', '285', 'soiree', 'speciale', 'zouk', 'nichols', 'parisfree', 'roses', '0794674629107880867867', 'removed', 'apply2', '08715203694', '88800', '89034', '08718711108', 'sun0819', 'posts', 'helloyou', 'seem', 'cool', '08452810071', 'lapdancer', 'bedroom', 'g2', '1da', '150ppmsg', '448712404000please', '08712404000', 'ngage', 'deck', 'wwwcnupdatescomnewsletter', 'alerts', '08714712388', '449071512431', '08714712394', 'alertfrom', 'jeri', 'stewartsize', '2kbsubject', 'lowcost', 'prescripiton', 'drvgsto', '82324', 'realize', 'thousands', 'running', 'tattoos', 'romantic', 'nights', '79', '08704439680tscs', 'unclaimed', '09066368327', 'closingdate040902', 'claimcode', 'm39m51', '150pmmorefrommobile2bremovedmobypobox734ls27yf', 'thought', 'living', 'perfect', '100psms', '087018728737', 'toppoly', 'tune', '81618', 'pole', '9996', '14thmarch', 'availa', 'rg21', '4jx', 'outbid', 'simonwatson5120', 'shinco', 'plyr', 'acsmsrewards', 'notifications', 'smsservices', 'yourinclusive', 'wed', 'voucherstext', 'nowsavamobmember', 'fall', 'worlds', '83110', 'virgin', 'mystery', '09061104283', 'approx', '07808', 'xxxxxx', '08719899217', 'posh', 'birds', 'chaps', 'trial', 'prods', 'champneys', 'put', 'dob', 'ta', '0721072', '09065171142stopsms08', 'downloaded', 'already', 'paid', 'httpdoit', 'mymoby', 'lastest', 'stereophonics', 'marley', 'dizzee', 'racal', 'libertines', 'strokes', 'nookii', 'bookmark', 'january', '1million', 'ppt150x3normal', 'box403', 'w1t1jy', 'matthew', '09063440451', '4lux', 'ppm150', 'box334', '09061749602', '528', 'hp20', '1yf', 'touch', 'folks', '150psms', 'stories', 'panasonic', 'bluetoothhdset', 'doublemins', 'doubletxt', '09065394514', '09058097218', 'flirting', 'bloke', 'zoe', 'wwwflirtpartyus', 'replys150', 'elvis', 'presleys', 'birthday', '449050000301', '09050000301', 'speed', '80155', 'em', 'swap', 'chatter', 'chat80155', 'rcd', 'taking', 'survey', 'however', '80160', 'wwwtxt43com', 'hmv1', 'requests', '1stchoicecouk', '08707808226', 'thank', 'notified', 'marketing', '84122', '08450542832', 'virgins', 'sexual', 'cute', '69911150p', 'celeb', '087016248', '08719181503', 'door', 'exp', '30apr', 'completely', 'accommodation', 'various', 'global', 'wwwphb1com', 'ph08700435505150p', '08712402779', '08718730555', 'set', '09096102316', '2moro', 'jane', '80488biz', 'videosound', 'gold', 'videosounds2', 'logosmusicnews', 'jamstercouk', '09701213186', 'sang', 'uptown', '80s', 'nick', 'tom', 'pete', 'dick', 'fact', 'types', 'win150ppmx3age16', 'dartboard', 'condition', 'doubles', 'trebles', 'optin', 'whats', 'bbc', 'charts', 'summers', 'finally', 'matched', 'help08714742804', 'havin', 'borin', '09099725823', 'bought', 'offering', '07801543489', 'latests', 'wordcollect', 'no83355', 'tcllc', 'nyusa', '150pmt', 'msgrcvd18', 'hubby', 'meetins', 'cumin', '09099726395', 'credited', 'www80488biz', '2channel', 'leadership', 'skills', 'strong', 'psychic', 'wquestion', 'vote', 'along', 'stars', 'karaoke', 'install', 'browse', 'artists', '10803', '08714719523', 'wwworangecoukow', '08719899230', 'olympics', 'rtking', 'pro', 'inforingtonekingcouk', '08701237397', 'redeemable', 'wwwringtonekingcouk', '02072069400', 'bx', '526', '0anetworks', 'allow', 'companies', 'responsible', 'suppliers', 'freemsgfeelin', 'kinda', 'lnly', 'jst', 'pictxt', 'rgent', 'lookin', 'daytime', 'busty', 'woman', 'sort', '09099726429', 'janinexx', '09050001295', 'a21', 'monthly', 'mobsicom', '391784', '0089my', 'four', 'digits', '09063442151', 'sufficient', 'prebook', 'trackmarque', 'infovipclub4u', 'mandy', 'sullivan', 'hotmix', 'fmyou', '500000', 'easter', 'drawplease', 'telephone', '09041940223', '290305', 'transferred', 'else', 'conacted', 'youto', '09111030116', 'pobox12n146tf15', 'brother', '09064018838', 'cro1327', '1225', '50award', 'hottest', 'wanting', 'hack', 'backdoor', 'rooms', 'fraction', 'neo69', '09050280520', 'subscribe', 'dps', 'bcm', '8027', '12price', 'xnet', 'mins100txtmth', '2optoutd3wv', '08718726970', 'prizeto', 'nearly', 'banned', '09058094594', '09061743811', '09090900040', 'extreme', 'dirty', 'office', 'total', 'privacy', 'knows', 'sic', 'listening', '60p', '247mp', '0870753331018', 'videopic', 'fones', 'wild', 'ill', 'hurry', '150prcvd', 'stop2stop', '08715500022', 'rpl', 'cnl', '08702490080', 'vpod', '09090204448', 'minded', 'evening', 'a150', 'minapn', 'ls278bb', '09065394973', '31', '2006', 'fifa', 'world', 'held', '09061743810', 'themobyo', 'yo', 'yohere', 'open', 'skillgame1winaweek', 'age16150ppermesssubscription', '09094100151', 'cast', 'gbp5month', 'box61m60', '1er', 'ages', '09066362220', 'wither', 'eg23f', 'eg23g', 'messagestext', 'nowuse', 'web2mobile', 'txt250com', 'box139', 'la32wu', 'txtx', '85233', 'freeringtonereply', 'help08700469649', 'box420', '087123002209am7pm', 'b4u', 'wc', '2703', 'marsms', 'wwwb4utelecom', '08717168528', 'buffy', 'qlynnbv', 'help08700621170150p', '449month', 'bundle', 'deals', 'avble', 'call2optoutj', 'mf', '08714712379', 'k718', '09065069120', 'ya', '4goten', 'bout', 'scammers', 'smartthough', 'regular', 'respond', 'prem', 'msgsubscription', 'nos', 'used', 'beware', '2morro', 'passion', '09099726481', 'dena', '1minmobsmorelkpobox177hp51fl', 'r836', '09065069154', 'splashmobile', 'subscrition', '88877free', '88877', '3pound', '2stoptx', '08718738034', '21', 'arrow', '08718726971', 'tddnewsletteremc1couk', 'thedailydraw', 'helen', 'dozens', 'prizeswith', '100603', '09066368753', '97n7qp', 'freenokia', 'or2optouthv9d', 'restrictions', 'buddys', 'sir', '08712402902', 'expired', 'resub', 'monoc', 'monos', 'polyc', 'stream', '0871212025016', 'draws', 'becausethey', '09058098002', 'pobox1', 'w14rg', 'nasty', 'thing', 'filthyguys', 'bitch', 'slo', 'slo4msgs', 'gotto', '08702840625', 'comuk220cm2', 'ithis', 'created', 'page', 'wwwasjesuscom', 'read', 'wrote', 'opinions', '83370', 'wwwmusictrivianet', 'sppok', 'complementary', 'wa14', '2px', 'sender', 'hol', 'hvae', '09061701444', '6230', 'pobox11414tcrw1', 'text82228', 'logos', 'wwwtxt82228com', 'infotxt82228couk', 'mini', 'snap', 'quizclub', '80122300pwk', 'sprwm', 'ph08704050406', 'gmw', 'connected', 'vid', 'keyword', 'ten', '83435', 'tarot', '85555', 'horniest', 'nytec2a3lpmsg150p', 'whose', 'wwwtklscom', 'stoptxtstop150week', 'cc100pmin', '0870737910216yrs', '150wk', '077xxx', '09066362206', 'w4', '5wq', 'park', 'nyt', 'response', '1mcflyall', 'ab', 'sara', 'jorgeshock', 'smithswitch', 'fans', 'str', '0870141701216', '4txt120p', 'europe', '10th', '09050000555', 'ba128nnfwfly150ppm', '83021', '20m12aq', 'lux', 'james', 'eh74rr', 'women', 'instantly', '69969', 'bcmsfwc1n3xx', 'footy', 'stadium', 'large', 'cocacola', 'walk', 'child', 'afraid', 'dark', 'become', 'teenager', 'wants', 'bin', 'instant', '08715203028', '9th', 'wins', '50500', 'freemsgfav', 'tonesreply', 'mobs', '2u', 'breathe1', 'crazyin', 'sleepingwith', 'finest', 'ymca', 'getzedcouk', 'pobox365o4w45wq', 'late', 'flowers', 'christmas', '505060', 'midnight', 'romcapspam', 'responding', 'presence', 'outgoing', 'bringing', 'breath', '08712103738', 'freemessage', 'jamsterget', 'frog', 'sound', 'mad1', 'mad2', 'sounds', 'gbpweek', '69855', 'stopbcm', 'sf', 'pdatenow', 'call2optoutyhl', '09058094454', 'package', 'resubmit', 'request', 'expiry', '08712400200', '08718723815', '27603', '08714714011', 'anyone', 'slower', 'idiot', 'faster', 'maniac', 'call2optout4qf2', 'professional', 'tiger', 'woods', '400minscall', 'call2optoutj5q', '69200', 'hrs', 'chrgd50p', '2exit', 'unsubscribed', 'tons', 'hunks', 'httpgotbabescouk', 'subscriptions', 'abroad', 'lonely', 'xxsp', 'stopcost', '08712400603', 'agent', 'loads', 'goodies', 'mat', 'lord', 'ringsreturn', 'nowreply', 'june', 'soundtrack', 'stdtxtrate', '28th', 'feb', '06', 'str8', 'classic', 'nokia150p', 'poly200p', 'clip', '35p', 'better', 'mmsto', '32323', 'vat', '09053750005', '310303', '08718725756', '140ppm', 'httpwwwetlpcoukreward', '88039skilgmetscs087147403231winawkage16150perwksub', '09066358361', 'y87', 'x29', '09065989180', '08718726978', '44', '7732584351', '09058097189', '5226', 'hava', '1131', 'rct', 'thnq', 'adrian', 'rgds', 'vatian', '09050000928', '07090201529', 'needs', '09066364349', 'lose', 'box434sk38wp150ppm18', 'msgwe', 'mistake', 'shortcode', '83332please', '08081263000', 'refundedthis', '08712402972', '09058095201', 'never', 'much', 'came', 'made', 'gbpsms', 'deltomorrow', '09066368470', 'begin', '24m', '1month', 'smartcall', '68866', 'subscriptn3gbpwk', '08448714184', 'stoptxt', 'landlineonly', 'textsweekend', 'orno', 'fink', 'met', '09099726553', 'promised', 'carlie', 'calls1minmobsmore', 'lkpobox177hp51fl', '89105', 'wedding', 'lingerie', 'wwwbridalpetticoatdreamscouk', 'superb', 'weddingfriend', 'knickers', 'beg', '01223585236', 'nikiyu4net', 'phone750', '09050000878', 'dorothykiefercom', '09071517866', '150ppmpobox10183bhamb64xe', '10am', '8pm', 'theyre', 'selling', 'fast', 'rock', 'chik', '100s', 'filth', 'saristar', 'e14', '9yt', '08701752560', '450p', 'stop2', '9061100010', 'wire3net', '1st4terms', 'mobcudb', '09050000460', 'j89', 'box245c2150pm', 'banneduk', 'round', 'highest', 'maximum', '71', 'bids', 'flight', '69101', 'wwwrtfsphostingcom', 'willing', 'strt', 'ltdhelpdesk', '02085076972', '09066660100', '2309', '07090298926', 'ref9307622', 'mytonecomenjoy', 'html', 'gbp450week', 'mfl', 'wamma', 'laidwant', 'doggin', 'dogs', 'nownyt', 'promotion', '8714714', '087147123779am7pm', 'x49', 'colourredtextcolourtxtstar', '2nights', 'wildest', '146tf150p', 'airport', 'lounge', 'passes', '08704439680', 'booking', 'quote', '09058095107', 's3xy', '08717895698', 'mobstorequiz10ppm', 'twinks', 'scallies', 'skins', 'jocks', '08712466669', '08712460324nat', '09061701851', 'k61', '12hours', '74355', 'row', 'concert', 'november', '09061104276', 'cost375max', 'single', 'nowsend', '62220cncl', 'stopcs', '08717890890150', 'ringtonefrom', 'wmlid1b6a5ecef91ff937819firsttrue180430jul05', 'oh', 'god', 'ive', 'found', 'glad', 'xafter', 'cst', 'chg', 'picture', 'httpalto18coukwavewaveaspo44345', 'call2optouthf8', '08719181259', 'xxxxx', '260305', 'freeringtone', 'real1', 'pushbutton', 'dontcha', 'babygoodbye', 'golddigger', 'webeburnin', 'gnarls', 'barkleys', 'totally', 'secured', 'unsecured', '195', '6669', '3000', 'ringtoneking', '84484', '087104711148', 'triple', 'echo', 'dial', 'bx526', 'x49your', 'accessible', '08709501522', '139', 'la3', '2wu', '150week', '09064017305', 'pobox75ldns7', 'tbspersolvo', 'chasing', 'for38', 'definitely', 'paying', 'ignore', 'kath', 'manchester', 'loans', 'bad', 'noworriesloanscom', '08717111821', 'season', '2wks', 'goals', 'villa', 'brings', 'heroes', 'tips', '07973788240', '08715203649', 'gsoh', 'spam', 'ladiesu', 'gigolo', 'mens', 'oncall', 'mjzgroup', '087143423992stop', 'msg150rcvd', '08707500020', 'ukp2000', '09061790125', 'spjanuary', 'simpsons', 'released', 'band', 'died', 'agreen', 'bblue', 'cred', 'amanda', 'regard', 'renewing', 'upgrading', 'tel', '3680', 'subject', 'httpwwwwtlpcouktext', '0906346330', '47', 'po19', '2ez', 'cmon', 'turn', 'sticky', 'replies', '0796xxxxxx', 'day2', 'prizeawaiting', 'called', 'left', '07008009200', '3750', 'colours', '241', '3lions', 'normal', 'gprs', 'accordingly', 'repeat', 'block', 'breaker', 'deluxe', 'format', 'features', 'graphics', 'bbdeluxe', 'challenge', '02', 'kit', 'strip', '1013', 'ig11', 'oja', '08712402578', 'thesmszonecom', 'anonymous', 'masked', 'messagesim', 'theredo', 'potential', 'abuse', '0789xxxxxxx', 'shy', '09058091870', 'complete', 'landmark', 'bob', 'barry', 'ben', '83738', 'tonexs', 'renewed', 'wwwclubzedcouk', 'billing', '8000930705', 'recpt', '13', 'processed', 'subscribers', 'gb', 'headset', 'adp', 'floppy', 'snappy', 'happy', 'ukmobiledate', 'giving', '08719839835', 'mgs', '89123', 'proze', 'norcorp', 'ltd150mtmsgrcvd18', 'items', '7cfca1a', 'wining', '946', 'wot', 'cock', 'hubbys', 'man', 'wife', '89938', 'strings', 'rec', '150ea', 'otbox', '731', 'la1', '7ws', 'sexiest', 'dirtiest', 'chatim', 'w8in', '4utxt', 'laugh', 'chitchat', 'logon', '8883', 'cm', '4217', 'w1a', '6zf', '118pmsg', '1000call', '09071512432', '300603tcsbcm4235wc1n3xxcallcost150ppmmobilesvary', '09065171142stopsms08718727870150ppm', 'recorder', 'canname', 'capital', 'australia', 'mquiz', '7634', '7684', 'ripped', 'wwwclubmobycom', '08717509990', 'polytruepixringtonesgames', '08718738002', '48922', '211104', '07099833605', 'ref9280114', 'chloe', 'smashed', 'missing', '150ptext', '07808726822', '08718729758', 'rayman', 'golf', 'activ8', 'key', 'termsapply', 'minstexts', 'coolmob', 'frogaxel', 'akonlonely', 'black', 'eyeddont', 'cashbincouk', 'wwwcashbincouk', 'continued', 'in2', 'president', '1172', '09066649731from', '09077818151', 'calls150ppm', '30s', 'wwwsantacallingcom', '0784987', '08719180219', '060505', 'videos', 'smsshsexnetun', 'fgkslpopw', 'fgkslpo', '0871277810710pmin', '08715203652', '42810', '29100', 'messagethanks', '150pmsgrcvd', 'skip', 'customercare', 'lyricalladie21f', 'yes910', 'no910', 'wwwsmsacuhmmross', 'ou', 'sn', 'pobox202', 'nr31', '7zs', '450pw', '83118', 'colin', 'farrell', 'swat', 'wkend', 'popcornjust', 'msgticketkioskvalid', '4712', 'kiosk', 'mre', 'scores', 'simple', 'shot', 'yards', 'bergkamp', 'margin', '78', 'sexychat', 'amy', 'couple', 'parties', 'select', 'benefits', 'trained', 'advisors', 'dialling', '402', 'meal', 'dining', 'experiencehttpwwwvouch4mecometlpdiningasp', '09058094507', 'unicefs', 'asian', 'tsunami', 'disaster', 'fund', 'texting', '864233', 'goldviking', '29m', 'yes762', 'no762', 'wwwsmsacugoldviking', 'phony', 'xxxx', '125', 'freeentry', 'xt', '08714712412', '150pmeg', '08715203685', 'code4xx26', '131004', 'deepest', 'darkest', '09094646631', 'natalie', '20f', 'yes165', 'no165', 'wwwsmsacunatalie2k9', '08701213186', '83039', '62735450', 'accommodationvouchers', 'mustprovide', '15541', '5p', 'tscs08714740323', '1winawk', '150perweeksub', '09066361921', 'themobhit', 'pink', 'panther', 'sugababes', 'zebra', 'animation', 'badass', 'hoody', 'wallpaperall', 'resent', 'previous', 'failed', 'error', 'queries', 'customersqueriesnetvisionukcom', '08715205273', 'vco', '078', 'ree', 'compensation', 'wwwtelediscountcouk', '08715203656', '42049', '261004', 'someonone', '09064015307', '09061790126', 'wwwldewcom1win150ppmx3age16subscription', 'textcomp', 'follows', 'subsequent', 'charged150pmsg2', '84128custcare', '09095350301', 'erotic', 'ecstacy', 'dept', '13404', '08717507382', 'datingi', 'two', 'started', 'radio', 'connection', 'coincidence', 'leading', '151', 'pause', 'gr8prizes', '8800', 'psp', 'wktxt', 'httpwwwgr8prizescom', '02070836089', '09058094583', '32000', 'legitimat', 'efreefone', 'wat', 'police', 'station', 'toilet', 'stolen', 'cops', 'sparkling', 'breaks', '45', 'person', '0121', '2025050', 'wwwshortbreaksorguk', 'wwwgambtv', 'wmlid820554ad0a1705572711firsttruec', '09050000332', '09064017295', '08448350055', 'planettalkinstantcom', 'marvel', 'ultimate', 'spiderman', 'spider', '83338', '8ball', '07808247860', '08719899229', '40411', '061104', '49557', '261104', 'gsex', '2667', 'wc1n', '3xx', '3mobile', 'chatlines', 'inclu', 'india', 'servs', 'sed', 'l8er', 'mega', 'giv', 'shit', 'bailiff', 'house', '087187272008', 'now1']\n",
            "Ham Hapaxes: ['jurong', 'amore', 'aids', 'patent', 'cried', 'breather', 'granted', 'fulfil', 'kim', 'gota', 'ffffffffff', 'forced', 'convincing', 'packing', 'ahhh', 'vaguely', 'apologetic', 'fallen', 'actin', 'spoilt', 'badly', 'fainting', 'housework', 'cuppa', 'timings', 'watts', 'arabian', 'steed', 'endowed', 'hep', 'immunisation', 'stubborn', 'sucker', 'suckers', 'thinked', 'smarter', 'crashing', 'accomodations', 'cave', 'offered', 'embarassing', 'mallika', 'sherawat', 'yesgauti', 'sehwag', 'burger', 'seekers', 'youhow', 'performed', 'peoples', 'shy', 'operate', 'tas', 'multis', 'factory', 'kanoil', 'casualty', 'stuff42moro', 'includes', 'telugu', 'moviewat', 'loans', 'hairdressers', 'beforehand', 'ams', '4the', 'signin', 'memorable', 'ip', 'minecraft', 'server', 'grumpy', 'lying', 'plural', 'dinnermsg', 'openin', 'formal', 'weighthaha', 'eggpotato', 'ratio', 'hmmmy', 'applespairsall', 'malarky', 'sao', 'predict', 'knowyetunde', 'involve', 'imposed', 'del', 'lucyxx', 'tmorrowpls', 'accomodate', 'yijuehotmailcom', 'nver', 'cozsomtimes', 'biggest', 'hearts', 'dot', 'ummmawill', 'inour', 'sindu', 'nevering', 'typical', 'dirt', 'chores', 'exist', 'hail', 'mist', 'aaooooright', 'meare', 'envy', 'sees', 'parentsi', 'excited', 'cultures', 'missunderstding', 'bridge', 'lager', 'axis', 'surname', 'clue', 'spanish', 'begins', 'goodfine', 'lifted', 'hopes', 'approaches', 'greatbye', 'handsome', 'finding', 'league', 'ors', 'stool', '1pm', 'babyjontet', 'enc', 'ga', 'alter', 'dogg', 'refund', 'kkgoodstudy', 'prediction', 'register', 'ubandu', 'diskyou', 'scenery', 'elama', 'mudyadhu', 'strict', 'gandhipuram', 'cross', 'rubber', 'youwhen', 'hearing', 'pleassssssseeeeee', 'sportsx', 'baig', 'watches', 'uve', 'ups', '3days', '2wks', 'usps', 'bribe', 'nipost', 'suzy', 'luton', '0125698789', 'h', 'sometme', 'evo', 'narcotics', 'objection', 'rob', 'mack', 'theater', 'celebrations', 'ahold', 'cruisin', 'dearshall', 'tonitebusy', 'streetshall', 'tonitethings', 'okvarunnathu', 'edukkukayee', 'raksha', 'ollubut', 'gurl', 'appropriate', 'diesel', 'fridge', 'womdarfull', 'remb', 'jos', 'bookshelf', 'waythis', 'uniquei', 'mylife', 'kkadvance', 'l8', 'guild', 'kkapo', 'kgood', 'evaporated', 'privacy', 'stealing', 'employers', 'tadaaaaa', 'wined', 'dined', '1000s', 'hiding', 'huiming', 'prestige', 'jeremiah', 'iphone', 'apeshit', 'safely', 'callingforgot', 'onam', 'sirjii', 'personmeet', 'insha', 'allahrakhesh', 'tata', 'aig', 'tisscotayseer', 'andrewsboy', 'chikkudb', 'audreys', 'sunshine', 'dawns', 'refreshed', 'z', 'uniform', 'spoil', 'lindsay', 'bars', 'heron', 'payasam', 'rinu', 'taught', 'becaus', 'verifying', 'prabu', 'repairs', 'followin', 'wallet', '945', 'owl', 'kickboxing', 'lap', '730ish', 'performance', 'award', 'calculated', 'monthnot', 'salam', 'wahleykkumsharing', 'newsby', 'tayseertissco', 'joinedhope', 'fineinshah', 'allahmeet', 'sometimerakheshvisitor', 'hmmmkbut', 'stoners', 'disastrous', 'fav', 'busetop', 'iron', 'okies', 'wendy', 'goal', 'yesfrom', 'siva', '1childish', '2naughty', '3sentiment', '4rowdy', '5ful', 'attitude', '6romantic', '7shy', '8attractive', '9funny', 'urination', 'hillsborough', 'shoul', 'txtjourney', 'gdnow', 'werethe', 'monkeespeople', 'monkeyaround', 'howdy', 'blimey', 'exercise', 'concentration', 'hanks', 'lotsly', 'kkwhat', 'detail', 'transferacc', 'optimistic', 'amy', 'consistently', 'practicum', 'links', 'ears', '120', 'feelingwavering', 'individualtime', 'heal', 'oral', 'slippery', 'bike', 'enters', 'removed', 'differ', 'differbe', 'ahwhat', 'machiany', 'whenre', 'mcr', 'jaykwon', 'thuglyfe', 'falconerf', 'faded', 'glory', 'ralphs', 'reunion', 'nowcan', 'accenture', 'jackson', 'rec', 'reache', 'nuerologist', 'lolnice', 'westshore', 'significance', 'gs', 'ammo', 'ak', 'nojst', 'sno', 'problematic', 'unconscious', 'adults', 'abnormally', 'rude', 'doublefaggot', 'bani', 'leads', 'buttons', 'famous', 'unconditionally', 'temper', 'oclock', 'bash', 'cooped', 'invitation', 'cali', 'weddin', 'alibi', 'sink', 'paces', 'cage', 'surrounded', 'cuck', 'weeddeficient', 'acknowledgement', 'astoundingly', 'tactless', 'oath', 'magic', 'silly', 'uv', 'causes', 'mutations', 'sunscreen', 'thesedays', 'lunchyou', 'onlinewhy', 'bao', 'sugardad', 'ahgee', 'meim', 'brownie', 'ninish', 'icky', 'freek', 'ridden', 'missy', 'goggles', 'arguing', 'arngd', 'walkin', 'unfortuntly', 'bites', 'frnt', 'sayin', 'exwife', 'jjc', 'tendencies', 'meive', 'gotany', 'srsly', 'yi', 'prix', 'stands', 'nitz', 'blastin', 'occur', 'rajnikant', 'oceand', 'bridgwater', 'banter', 'bestrply', 'dependents', 'thanx4', 'cer', 'soonc', 'himthen', 'hundreds', 'handsomes', 'beauties', 'aunties', 'shock', 'friendships', 'grow', 'dismay', 'concerned', 'tootsie', 'seventeen', 'hundred', 'ml', 'biola', 'fetching', 'restock', 'brighten', 'allo', 'braved', 'triumphed', 'bham', 'uncomfortable', 'sonetimes', 'rough', 'wesleys', 'dealers', 'cloud', 'wikipediacom', 'repent', 'positions', 'kama', 'sutra', 'nange', 'bakra', 'kalstiyathen', 'teacoffee', 'carlosll', 'lakhs', 'ditto', 'wetherspoons', 'piggy', 'freaky', 'scrappy', 'sdryb8i', 'crying', 'imprtant', 'tomorw', 'dearme', 'cherthalain', 'bfore', 'starti', 'accordinglyor', 'comingtmorow', 'engaged', '1405', '1680', '1843', 'purchase', 'entrepreneurs', 'alexs', 'corporation', 'ku', 'prevent', 'dehydration', 'fluids', 'soso', 'smsd', 'trek', 'harri', 'shitstorm', 'attributed', 'sth', 'specs', 'membership', 'px3748', 'macha', 'upseti', 'mindsetbelieve', 'uslet', 'againcall', 'sfine', 'wondar', 'flim', 'jelly', 'stillmaybe', 'sameso', 'itor', 'admiti', 'madthen', 'correctionor', 'lifeand', 'worldmay', 'runninglets', 'scrumptious', 'dao', 'jide', 'visiting', 'steak', 'convincingjust', 'neglect', 'itjust', 'opportunityall', 'fastpls', 'prayers', 'dearrakhesh', 'hadnt', 'clocks', 'realised', 'wahay', 'gaze', 'caveboy', 'sorryi', 'faith', 'possiblehope', 'worklove', 'beautifulmay', 'christmasmerry', 'youcarlos', 'isare', 'vibrate', 'acting', 'grandmas', 'hungover', 'gua', 'faber', 'dramatic', 'hunting', 'drunkard', 'idc', 'weaseling', 'trash', 'punish', 'beerage', 'randomlly', 'fixes', 'spelling', 'fondly', 'ywhere', 'dogbreath', 'sounding', 'weighed', 'woohoo', 'uncountable', 'petey', 'whereare', 'friendsare', 'thekingshead', 'canlove', 'dled', 'smokin', 'boooo', 'ssnervous', 'costumes', 'yowifes', 'youi', 'dobby', 'enjoyin', 'yourjob', 'hunnyhope', 'illspeak', 'soonlots', 'xxxx', 'starshine', 'sips', 'bits', 'turned', 'burial', 'rv', 'hol', 'roadsrvx', 'comprehensive', 'prashanthettans', 'samantha', 'guitar', 'impress', 'doug', 'realizes', 'trauma', 'swear', 'officewhats', 'mattermsg', 'inner', 'tigress', 'activate', 'babyhope', 'urfeeling', 'bettersn', 'probthat', 'overdose', 'lovejen', 'ana', 'sathy', 'rto', 'spoons', 'corvettes', 'bunkers', 'philosophical', 'hole', 'goodno', 'problembut', 'atleast', 'shakespeare', 'woul', 'curfew', 'gibe', 'getsleep', 'studdying', 'massages', 'yoyyooo', 'permissions', 'unsoldmike', 'hussey', 'faglord', 'nutter', 'cutter', 'ctter', 'cttergg', 'cttargg', 'ctargg', 'ctagg', 'thus', 'superb', 'grateful', 'happier', 'agents', 'experiment', 'invoices', 'smell', 'tobacco', 'assumed', 'grinule', 'fudge', 'oreos', 'zahers', 'nauseous', 'dieting', 'reminder', 'ashleys', 'avalarr', 'hollalater', 'rounds', 'todaybut', 'websitenow', 'blogging', 'magicalsongsblogspotcom', 'chikkuil', 'slices', 'kvb', 'fridayhope', 'alternativehope', 'congratulations', 'ore', 'owo', 'fro', 'samus', 'shoulders', 'vomitin', 'kkare', 'stuffed', 'writhing', 'tons', 'paypal', 'voila', 'pockets', 'sorta', 'blown', 'scores', 'sophas', 'secondary', 'applying', 'ogunrinde', 'lodging', 'chk', 'ms', 'dict', 'shb', 'dobbys', 'retired', 'code', 'natwest', 'chad', 'gymnastics', 'christians', 'backa', 'token', 'youthats', 'likingbe', 'seeno', 'thatdont', 'aptitude', '215', 'horse', 'wrongly', 'borin', 'boggy', 'biatch', 'hesitate', 'weakness', 'notebook', 'eightish', 'carpark', 'ahthe', 'tomorrowcall', '67441233', 'ireneere', 'bus822656166382', 'cresubi', 'park6ph', '5wkg', 'daysn', 'sd', '26th', 'july', 'relaxing', '7am', '5ish', 'stripes', 'skirt', 'escalator', 'beth', 'charlie', 'helen', 'nobut', 'syllabus', '730pm', 'poyyarikaturkolathupalayamunjalur', 'posterode', 'heroi', 'apt', 'opportunitypls', 'ltemailgt', 'meat', 'supreme', 'toldshe', 'dearregret', 'cudnt', 'calldrove', 'ctla', 'homeleft', 'carente', 'ishtamayoohappy', 'bakrid', 'knowwait', 'glorious', 'finds', 'content', 'coaxing', 'images', 'fond', 'souveniers', 'cougarpen', 'scratches', 'no1', 'nanny', 'zoe', 'shitin', 'defo', 'hardest', 'millions', 'lekdog', 'blankets', 'sufficient', 'atten', 'soiree', 'data', 'analysis', 'belligerent', 'les', 'rudi', 'snoringthey', 'ink', '515', 'howre', 'throwing', 'processnetworking', 'daysso', 'finalise', 'visitneed', 'dentist', 'lul', 'nurses', 'obese', 'oyea', 'ami', 'parchi', 'kicchu', 'kaaj', 'korte', 'iccha', 'korche', 'tul', 'dvd', 'copies', 'sculpture', 'surya', 'pokkiri', 'attractioni', 'meshe', 'thoughtsi', 'hershe', 'dreamlove', 'breath', 'namemy', 'hermy', 'herwill', 'sorrowsi', 'proove', 'planeti', 'praises', 'makiing', 'sambarlife', 'thenwill', 'needle', 'meetitz', '4few', 'conected', 'spatula', 'calis', 'complexities', 'freely', 'taxes', 'outrageous', 'ryder', 'unsoldnow', 'strips', 'postal', 'addressull', 'alrightokay', 'gifts', 'cliff', 'wrking', 'sittin', 'drops', 'hen', 'smoked', 'sfirst', 'timedhoni', 'teju', 'hourish', 'nothis', 'groundamla', 'convenience', 'evaluation', 'cheyyamoand', 'throws', 'errors', 'correction', 'painhope', 'tau', 'piah', 'ohas', 'shades', 'copied', 'sitter', 'kaitlyn', 'adult', 'danger', 'peeps', 'comment', 'veggie', '2000', 'neighbors', 'computerless', 'balloon', 'passthey', 'ntswt', 'drms', 'melody', 'macs', 'hme', 'islands', 'velachery', 'flippin', 'breaking', 'cstore', 'hangin', 'alivebetter', 'lodge', 'worrying', 'quizzes', 'popcorn', 'thin', 'faultal', 'arguments', 'faultfed', 'himso', 'thanxxx', 'semi', 'maaaan', 'guessin', 'ilol', 'personally', 'wuldnt', 'lunchtime', 'organise', 'passable', 'phd', '5years', 'prakesh', 'betta', 'aging', 'products', 'submitting', 'snatch', 'hellodrivby0quit', 'edrunk', 'iff', 'pthis', 'senrddnot', 'dancce', 'drum', 'basqihave', '2nhite', 'ros', 'xxxxxxx', 'relieved', 'westonzoyland', 'greatness', 'europe', 'goin2bed', 'only1more', 'mc', '2nitetell', 'every1', 'ava', 'goodtimeoli', 'melnite', 'ifink', 'sortedbut', 'everythin', 'monl8rsx', 'shun', 'bian', 'glass', 'exhibition', 'el', 'nino', 'chikkugoing', 'downstem', 'wahala', 'inperialmusic', 'listening2the', 'byleafcutter', 'johnsounds', 'insects', 'molestedsomeone', 'plumbingremixed', 'evil', 'acid', 'didntgive', 'bellearlier', 'cheery', 'collected', 'weirdo', 'stalk', 'profiles', 'heygreat', 'dealfarm', '9am', '95pax', 'deposit', '16', 'jap', 'disappeared', 'certificate', 'publish', 'wheellock', 'destination', 'fifty', 'settling', 'happenin', 'cocksuckers', 'ipads', 'worthless', 'novelty', 'items', 'tshirt', 'janx', 'designation', 'developer', 'spirit', 'shattered', 'girlie', 'colours', 'darker', 'styling', 'gray', 'remembr', 'listn', 'watevr', 'whileamp', 'minus', 'paragraphs', 'coveragd', 'vasai', '4o', 'retard', 'bathroom', 'icic', 'syria', 'heartsnot', 'gauge', 'pattys', 'mondaynxt', 'completing', 'ax', 'surgical', 'emergency', 'unfolds', 'korean', 'leonas', 'fredericksburg', 'que', 'pases', 'un', 'buen', 'tiempo', 'compass', 'worldgnun', 'way2smscom', 'baaaaabe', 'misss', 'youuuuu', 'convince', 'witot', 'buyer', 'melike', 'becz', 'undrstndng', 'avoids', 'suffer', 'steamboat', 'forgive', 'tp', 'bbq', '6ish', 'everyso', 'panicks', 'outhave', 'auntie', 'huai', 'path', 'appear', 'paths', 'reserve', 'thirunelvali', 'evei', 'netno', 'availablei', 'tackle', 'tonght', 'ploughing', 'pile', 'ironing', 'chinky', 'wi', 'nz', 'geelater', 'aust', 'bk', 'recharged', 'papa', 'detailed', 'losers', 'beta', 'kkany', 'noncomittal', 'snickering', 'chords', 'nofew', 'beforewent', 'boyf', 'interviw', 'worriedx', 'spreadsheet', 'whose', 'determine', 'entire', 'recognises', 'wisheds', 'intrepid', 'duo', 'breeze', 'fresh', 'twittering', 'yagoing', 'ducking', 'chinchillas', 'function', 'headstart', '230ish', 'earlierwe', 'rummer', 'flying', 'thanks2', 'rajini', 'spys', 'yalru', 'astne', 'innu', 'mundhe', 'ali', 'halla', 'bilo', 'marriageprogram', 'edhae', 'ovr', 'chikkuali', 'vargu', 'meow', 'meowd', 'prone', 'permission', 'dose', 'tablet', 'incomm', 'waitshould', 'lotr', 'maps', 'tiring', 'concentrating', 'browsin', 'compulsory', 'investigate', 'moneyas', 'youmoney', 'thinghow', 'vitamin', 'crucial', 'someones', 'hostbased', 'idps', 'linux', 'systems', 'converter', 'sayy', 'peteis', 'leannewhat', 'format', 'disc', 'champ', 'glasgow', 'kall', 'bestcongrats', 'lovin', 'corect', 'speling', 'hicts', 'employee', 'nike', 'sooo', 'shouting', 'dang', 'earliest', 'nordstrom', 'conference', 'degree', 'bleak', 'shant', 'nearer', 'raiden', 'totes', 'pierre', 'cardin', 'establish', 'truro', 'ext', 'worryuse', 'cloth', 'packalso', 'sunroof', 'blanked', 'image', 'kalainar', 'officethenampet', 'nosy', 'reacting', 'freaked', 'satanic', 'imposter', 'meneed', 'priceso', 'itmay', 'destiny', 'companion', 'chef', 'listener', 'organizer', 'sympathetic', 'athletic', 'courageous', 'determined', 'dependable', 'psychologist', 'pest', 'exterminator', 'psychiatrist', 'healer', 'stylist', 'aaniye', 'pudunga', 'venaam', 'chez', 'jules', 'hhahhaahahah', 'nig', 'leonardo', 'dereks', '2years', 'strain', 'withdraw', 'anyhow', 'millers', 'spark', 'rawring', 'xoxo', 'somewhr', 'crushes', 'honeymoon', 'outfit', 'cheque', 'leo', 'patty', 'donewant', 'haul', 'wildlife', 'want2come', 'that2worzels', 'wizzle', 'shanghai', '21st', 'cya', '645', 'thnx', 'sef', 'anjie', 'fring', 'talents', 'animal', 'shiny', 'warming', 'french', 'fooled', 'comedycant', 'keen', 'dammit', 'wright', 'fly', 'somewhat', 'laden', 'wrecked', 'six', 'spontaneously', 'goodevening', 'sif', 'spageddies', 'phasing', 'fourth', 'dimension', 'yesbut', 'meaningful', 'lines', 'compromised', 'lmaonice', 'dub', 'je', 'toughest', 'squatting', 'sonathaya', 'soladha', 'cd', 'raping', 'dudes', 'weightloss', 'mushy', 'embarrassed', 'stash', 'priya', 'kilos', 'accidant', 'tookplace', 'ghodbandar', 'slovely', 'ahnow', 'wherebtw', 'nus', 'sc', 'specialise', 'wad', 'desparately', 'stereo', 'mi', 'classmates', 'firesare', 'missionary', 'entertaining', 'hugh', 'laurie', 'praps', 'jon', 'spain', 'dinero', '12000pes', '48', 'hunnywot', 'bedroomlove', 'complaining', 'finns', 'downon', 'theacusations', 'itxt', 'iwana', 'wotu', 'thewend', 'haventcn', 'agesring', 'nething', 'satlove', 'dine', 'vtired', 'services', 'inspection', 'nursery', 'detailsi', 'youmy', 'follow', 'itmail', 'panren', 'paru', 'chuckin', 'trainners', 'carryin', 'bac', 'gooddhanush', 'needing', 'chikkusimple', 'habbahw', 'dileepthank', 'muchand', 'supportvery', 'hereremember', 'venugopal', 'mentionedtomorrow', 'latei', 'theregoodnight', 'remembrs', 'everytime', '3230', 'textbook', 'algorithms', 'edition', 'recharge', 'yessura', 'tvlol', '4ui', 'intend', 'iwasmarinethats', 'itried2tell', 'urmomi', 'careabout', 'learned', 'fake', 'iraq', 'afghanistan', 'stable', 'honest', 'traveling', 'blessget', 'pai', 'seh', 'parts', 'walsall', 'tue', 'terry', 'chatting', 'ccna', 'shrek', '3db', 'fellow', 'somethings', 'dying', 'lifting', 'teresa', 'dec', 'yould', 'bam', 'aid', 'usmle', 'squishy', 'mwahs', 'prominent', 'cheek', 'september', 'norm', '415', 'comingdown', 'dagood', 'murali', 'playerwhy', 'sts', 'engalnd', 'mia', 'elliot', 'kissing', 'wiproyou', 'matric', '850', '650', 'payments', 'fedex', 'kyou', 'reception', 'consensus', 'entertain', 'tag', 'bras', 'strewn', 'pillows', 'weaknesses', 'exposes', 'pulls', 'wicked', 'sh', 'readyall', 'supports', 'srt', 'ps3', 'jontin', 'pen', 'biro', 'unconsciously', 'unhappy', 'jog', 'lark', 'stations', 'lim', 'parachute', 'placed', 'lambda', 'angels', 'snowball', 'ello', 'ofice', 'oficegot', 'duffer', 'grr', 'pharmacy', 'cook', 'fffff', 'lifebook', 'zhong', 'qing', 'act', '46', 'accordingly', 'hypertension', 'mineall', 'annoyin', 'nigro', 'scratching', 'anyplaces', 'priority', 'ecstasy', 'hittng', 'reflex', '1010', 'adewale', 'egbon', 'minstand', 'mary', 'deduct', 'wrks', 'monkey', 'asshole', 'grab', 'sliding', 'payback', 'tescos', 'feathery', 'bowa', 'infra', 'gep', 'shhhhh', 'related', 'arul', 'amk', 'length', 'santha', 'corrct', 'dane', 'baskets', 'rupaul', 'practising', 'curtsey', 'memory', 'converted', 'ssindia', 'african', 'soil', 'roles', 'community', 'outreach', '8lb', '7oz', 'brilliantly', 'forwarding', 'intention', 'visitors', 'rules', 'bend', 'thia', 'inlude', 'previews', 'ambrithmaduraimet', 'dha', 'marrgeremembr', 'kitty', 'shaved', 'anybodys', 'tactful', 'eggspert', 'potato', 'crammed', 'satsgettin', '447per', 'apologize', 'admit', 'pei', 'subtoitles', 'jot', 'storelike', 'cereals', 'gari', 'bold2', 'thkin', 'resubbing', 'shadow', 'breadstick', 'saeed', 'redim', 'blueu', 'purpleu', 'pinku', 'orangei', 'lyk', 'greeni', 'yelowi', 'blackim', 'browni', 'arranging', 'eldest', 'drugdealer', 'wondarfull', 'hunonbus', 'donyt', 'homebut', 'latelyxxx', 'ownyouve', 'stressed', 'skallis', 'soooo', 'provider', 'cutest', 'dice', 'howda', 'mathe', 'samachara', 'audrie', 'autocorrect', 'simulate', 'readiness', 'andor', 'lara', 'supplies', 'guesses', 'attach', 'washob', 'nobbing', 'nickey', 'platt', 'ryan', 'spotty', 'province', 'sterling', 'problemfree', 'hall', 'term', 'hesitation', 'intha', 'ponnungale', 'ipaditan', 'rejected', 'noisy', 'needa', 'sfrom', 'manual', 'processits', 'reset', 'troubleshooting', 'strongly', 'beg', 'creativity', 'stifled', 'requirements', 'strangersaw', 'dave', 'nowstill', 'bloke', 'mrur', '2getha', '8830', 'nosh', 'waaaat', 'lololo', 'tables', 'occupied', 'comei', 'documents', 'submitted', 'stapati', 'cutie', 'hills', 'honesty', 'specialisation', 'labor', 'shakara', 'beggar', 'smashed', 'dent', 'crickiting', 'imin', 'towndontmatter', 'urgoin', 'outl8r', 'yavnt', 'original', 'popping', 'ibuprofens', 'sip', 'grown', 'chinatown', 'porridge', 'claypot', 'yam', 'fishhead', 'beehoon', 'jaklin', 'nearby', 'cliffs', 'ooh', '4got', 'moseley', 'weds', 'thankyou', 'pendingi', 'dayswill', 'thrurespect', 'homecheck', 'loveable', 'eternal', 'noble', 'truthful', 'intimate', 'enamous', 'textin', 'amigos', 'burn', 'progress', 'werent', 'arty', 'collages', 'tryin', '2hrs', 'waliking', 'cartons', 'shelves', 'mirror', 'jod', 'keris', 'smidgin', 'collegexx', 'intentions', 'accordin', 'knocking', 'sicomo', 'nolistened2the', 'plaid', 'albumquite', 'gdthe', 'air1', 'hilariousalso', 'boughtbraindancea', 'compofstuff', 'aphexs', 'abel', 'nelson', 'bbs', 'unmits', 'newspapers', 'yummmm', 'puzzeles', 'include', 'threats', 'sales', 'shifad', 'raised', 'official', 'doctors', 'reminds', '2godid', 'dust', 'watchin', 'lifetime', 'meaningless', 'alls', 'brdget', 'jones', 'inever', 'hmmbad', 'newshype', '700', 'studio', 'takenonly', 'bedrm900', 'velly', 'marking', 'vai', 'hanger', 'blanket', 'significant', 'waqt', 'pehle', 'naseeb', 'zyada', 'kisi', 'ko', 'kuch', 'miltazindgi', 'hum', 'sochte', 'zindgi', 'jeetey', 'stalking', 'reminded', 'varaya', 'elaya', 'anand', 'offers', 'beach', 'expected', 'deadwell', 'jez', 'iscoming', 'todo', 'workand', 'whilltake', 'zogtorius', 'financial', 'problemi', 'alian', 'posible', 'century', 'cm', 'frwd', 'sorts', 'owned', 'possessive', 'nohe', 'clarification', 'coimbatore', 'opinions', 'categories', 'ethnicity', 'census', 'transcribing', 'cakes', 'goodmate', 'asusual1', 'cheered', 'franyxxxxx', 'batt', 'gained', 'pressure', 'limits', 'doke', 'laying', 'neshanthtel', 'byatch', 'whassup', 'cl', 'chiong', 'dialogue', 'reltnship', 'pose', 'comb', 'dryer', 'fps', 'computational', 'madamregret', 'disturbancemight', 'dlf', 'premaricakindly', 'informedrgdsrakheshkerala', 'err', '8pm', 'kbut', 'hitteranyway', 'offline', 'anjolas', 'txting', 'directors', 'lac', 'deposited', 'taxless', 'suply', 'projects', 'imf', 'blocked', 'corrupt', 'itna', 'karo', 'pura', 'padhegm', 'torrents', 'particularly', 'slowing', 'commit', 'rightio', '1148', 'brum', 'scorable', 'paranoid', 'brin', 'sheet', 'kgive', 'complain', 'onlybettr', 'bsnl', 'offc', 'payed', 'suganya', 'dessert', 'abeg', 'profit', 'sponsors', 'onum', 'candont', 'poet', 'imaginationmy', 'carso', 'rr', 'famamus', 'locks', 'jenne', 'easiest', 'barcelona', 'kdo', 'daurgent', 'pansy', 'jungle', 'kanji', 'drinkpa', 'srs', 'drizzling', 'appointments', 'excused', 'drama', 'plsi', 'struggling', 'placeno', 'ego', 'necessity', 'gowait', 'reppurcussions', 'cosign', 'hcl', 'requires', 'freshers', 'processexcellent', 'neededsalary', 'mssuman', 'telephonic', 'bids', 'restuwud', 'reliant', 'fwiw', 'afford', 'kanowhr', 'sq825', 'arrival', 'citylink', 'props', 'pleasant', 'statements', 'bognor', 'splendid', 'yesim', 'ktv', 'misplaced', 'computers', 'begun', 'registration', 'permanent', 'residency', 'claire', 'risks', 'benefits', '6months', 'hmmmhow', 'predicting', 'accumulation', 'programs', 'belongs', 'herwho', 'fated', 'shoranur', 'fuelled', 'concern', 'prior', 'grief', 'honestly', 'promptly', 'burnt', 'someplace', 'goods', 'pressies', 'ultimately', 'tor', 'motive', 'tui', 'achieve', 'korli', 'dock', 'rolled', 'newscaster', 'dabbles', 'flute', 'wheel', 'the4th', 'october', 'elaborating', 'safety', 'aspects', 'oursso', 'youany', 'flow', 'developed', 'ovarian', 'cysts', 'shrink', 'onit', 'upping', 'grams', 'timin', 'apes', 'ibm', 'hp', 'gosh', 'spose', 'rimac', 'arestaurant', 'squid', 'dosomething', 'ucall', 'wrki', 'dabooks', 'nite2', 'eachother', 'luckily', 'starring', 'restocked', 'smoothly', 'challenging', 'pple700', 'nightsexcellent', 'breakfast', 'hamper', 'reality', 'daal', 'unni', 'rechargerakhesh', 'lacking', 'particular', 'dramastorms', 'forfeit', 'digi', 'coupla', 'wks', 'sundayish', 'held', 'prasad', 'rcbbattle', 'kochi', 'checkup', 'smear', 'gobi', 'pandy', '4w', 'technologies', 'todayhe', 'olowoyey', 'uscedu', 'argentina', 'taxt', 'massagetiepos', 'lool', 'taylors', 'shaking', 'timeslil', 'busyi', 'scarcasim', 'naal', 'eruku', 'chikkuwat', 'impressively', 'sensible', 'alsoor', 'danalla', 'obedient', 'ft', 'combination', 'needy', 'playng', 'yupz', 'modelsony', 'ericson', 'der', 'luks', 'modl', 'cheesy', 'frosty', 'witin', 'nudist', 'themed', 'pump', 'signal', 'unusual', 'palm', 'printing', 'handing', 'stated', 'perpetual', 'dd', 'pract', 'flung', 'justbeen', 'overa', 'brains', 'mush', 'tunde', 'missions', 'avo', 'crashed', 'cuddled', 'chachi', 'pl', 'tiz', 'kanagu', 'prices', 'ringing', 'houseful', 'brats', 'pulling', 'nowonion', 'derp', 'abusers', 'lipo', 'easter', 'netflix', 'clash', 'arr', 'oscar', 'rebtel', 'firefox', 'user', 'impressed', 'funs', 'teluguthts', 'replacing', 'ordered', 'mittelschmertz', 'paracetamol', 'salespee', 'arrived', 'cthen', 'conclusion', 'references', 'atyour', 'rugby', 'affidavit', 'twiggs', 'courtroom', 'showers', 'possessiveness', 'poured', 'golden', 'lasting', 'wtc', 'weiyi', 'private', 'godtaken', 'teethis', 'paining', 'maggi', 'mee', 'nasty', 'cough', 'com', 'bbdpooja', 'pimpleseven', 'blackand', 'sweatter', 'ambitious', 'miiiiiiissssssssss', 'tunji', 'misscall', 'frndz', '6missed', 'wipro', 'tall', 'robs', 'avenge', 'choices', 'toss', 'gudni8', 'dancin', 'explicitly', 'nora', 'smith', 'gayle', 'crucify', 'butting', 'vs', 'cedar', 'durham', 'reserved', 'wall', 'printer', 'groovy', 'groovying', 'harishs', 'transfred', 'acnt', 'nowadayslot', 'showroomscity', 'shaping', 'attending', 'doinat', 'callon', 'rons', 'kkyesterday', 'configure', 'settings', 'anal', 'pears', 'summer', 'oooooh', 'thatnow', 'mint', 'uxxxx', 'humans', 'studyn', 'everyboy', 'xxxxxxxx', '532', '924', '863', '725', 'brilliant1thingi', 'answr', 'liquor', 'loko', 'lined', 'laughs', 'fireplace', 'icon', 'fifth', 'woozles', 'weasels', 'machines', 'ignorant', 'mys', 'downs', 'fletcher', 'teaching', 'bowls', 'cozy', 'nightnobody', 'buzzzz', 'vibrator', 'shake', 'trends', 'pros', 'cons', 'description', 'nuclear', 'fusion', 'iter', 'jet', 'nonenowhere', 'ikno', 'doesdiscountshitinnit', 'jabo', 'hadya', 'sapna', 'manege', 'yday', 'hogidhechinnu', 'swalpa', 'agidhane', 'sports', 'typelyk', 'footblcrckt', 'swell', 'tim', 'bollox', 'tol', 'ingredients', 'pocy', 'non', 'senor', 'giggle', 'possibly', 'person2die', 'nvq', 'grinder', 'youkwhere', 'buyers', 'figuring', 'entirely', 'knowhe', 'disconnected', 'onluy', 'matters', 'offcampus', 'rileys', 'ew', 'wesley', 'howve', 'lingo', 'medont', 'lm', 'approaching', 'sankranti', 'republic', 'shivratri', 'ugadi', 'fools', 'independence', 'friendshipmotherfatherteacherschildrens', 'festival', 'dasara', 'mornings', 'afternoons', 'rememberi', 'theseyours', 'lifeis', 'daywith', 'thoughts', 'somewheresomeone', 'tosend', 'greeting', 'selflessness', 'initiate', 'tallent', 'wasting', 'portal', 'dont4get2text', 'lennon', 'bothering', 'shorethe', 'fox', 'frndsship', 'dwn', 'slaaaaave', 'summon', '3365', 'appendix', 'slob', 'gudnite', 'topicsorry', 'webpage', 'yeesh', 'gopalettan', 'participate', 'kkfrom', 'ay', 'steal', 'isaiahd', 'expert', 'ssi', 'thinl', 'sachinjust', 'importantly', 'tightly', 'wnevr', 'fal', 'fals', 'yen', 'madodu', 'nav', 'pretsorginta', 'nammanna', 'pretsovru', 'alwa', 'homelove', 'staffsciencenusedusgphyhcmkteachingpc1323', 'emigrated', 'hopeful', 'olol', 'stagwood', 'winterstone', 'victors', 'jp', 'mofo', 'pathaya', 'enketa', 'maraikara', 'priest', 'reserves', 'intrude', 'walkabout', 'cashed', 'announced', 'blog', 'footie', 'blow', 'phil', 'neville', 'abbey', 'returning', 'auctionpunj', 'pre', 'sacked', 'barred', 'lifethis', 'twat', 'dungerees', 'decking', 'punch', 'mentionned', 'onlydon', 'hogolo', 'gold', 'kodstini', 'madstini', 'hogli', 'mutai', 'eerulli', 'kodthini', 'thasa', 'messed', 'upyeh', 'tex', 'mecause', 'werebored', 'okden', 'uin', 'satsounds', 'likeyour', 'gr8fun', 'updat', 'countinlots', 'xxxxx', 'l', 'tagged', 'arrive', 'hdd', 'casing', 'mystery', 'opened', 'describe', 'asus', 'randomly', 'reformat', 'leu', 'plumbers', 'wrench', 'bcum', 'films', 'appeal', 'thriller', 'director', 'elephant', 'shove', 'um', 'cr', 'pookie', 'youdearwith', 'loverakhesh', 'nri', 'x2', 'unique', 'deserve', 'diddy', 'neighbor', 'toothpaste', 'oneta', 'poking', 'deam', 'conditions', 'coccooning', 'mus', 'yeahand', 'newquaysend', 'goneu', '1im', 'talkin', 'boutxx', 'divorce', 'windy', 'knowthis', 'tirunelvai', 'dusk', 'puzzles', 'stairs', 'phews', 'thangamits', 'recycling', 'earning', 'toledo', 'tai', 'feng', 'reservations', 'swimsuit', 'squeeeeeze', 'frndshp', 'luvd', 'themp', 'volcanoes', 'erupt', 'arise', 'hurricanes', 'sway', 'aroundn', 'disasters', 'lighters', '7pm', 'kkits', 'goodwhen', 'lasagna', 'chickened', 'woould', 'city', 'drove', 'shore', 'onedge', 'raviyog', 'peripherals', 'bhayandar', 'sunoco', 'musical', 'plate', 'leftovers', 'caller', 'starving', 'fatty', 'badrith', 'chennaii', 'usno', 'owe', 'checkin', 'numberso', 'ittb', 'block', 'armenia', 'swann', '330', '1120', '1205', 'justify', 'hunt', 'everyones', 'babysitting', 'itll', 'gonnamissu', 'buttheres', 'aboutas', 'merememberin', 'asthere', 'ofsi', 'breakin', 'yaxx', 'poortiyagi', 'odalebeku', 'hanumanji', '1hanuman', '2bajarangabali', '3maruti', '4pavanaputra', '5sankatmochan', '6ramaduth', '7mahaveer', 'janarige', 'ivatte', 'kalisidare', 'olage', 'ondu', 'keluviri', 'maretare', 'inde', 'dodda', 'problum', 'nalli', 'siguviri', 'idu', 'matra', 'neglet', 'ijust', 'talked', 'opps', 'tts', 'gei', 'tron', 'dl', 'selfish', 'spiffing', 'workage', 'craving', 'supose', 'babysit', 'therexx', 'spaces', 'embassy', 'lightly', 'checkboxes', 'hardcore', 'hundredhe', 'batsman', 'yettys', 'approx', '21', 'emailed', 'yifeng', 'theyll', 'slurp', '3miles', 'ing', 'brainless', 'dolld', 'vehicle', 'sariyag', 'madoke', 'barolla', 'postponed', 'stocked', 'tiime', 'tears', 'afternon', 'interviews', 'resizing', 'opposed', 'somerset', 'overtime', 'nigpun', 'dismissial', 'screwd', 'bull', 'floating', 'heehee', 'arithmetic', 'percentages', 'chillaxin', 'das', 'iknow', 'wellda', 'peril', 'studentfinancial', 'crisisspk', 'monster', 'obey', 'uhhhhrmm', 'youphone', 'athome', 'youwanna', 'jack', 'sayask', 'helpful', 'pretend', 'hypotheticalhuagauahahuagahyuhagga', 'brainy', 'occasion', 'celebrated', 'reflection', 'values', 'affectionsamp', 'traditions', 'cantdo', 'anythingtomorrow', 'myparents', 'aretaking', 'outfor', 'katexxx', 'level', 'gate', 'board', 'overheating', 'reslove', 'inst', '8o', 'western', 'nowadays', 'notixiquating', 'laxinorficated', 'bambling', 'entropication', 'oblisingately', 'opted', 'masteriastering', 'amplikater', 'fidalfication', 'champlaxigating', 'atrocious', 'wotz', 'junna', 'accident', 'a30', 'divert', 'wadebridgei', 'vill', 'orc', 'seeking', 'dayexcept', 'wherres', 'resolution', 'replybe', 'frankgood', 'logoff', 'parkin', 'asa', 'prince', 'charming', 'mention', 'served', 'arnt', 'xxxxxxxxxxxxxx', 'alle', 'moneeppolum', 'pole', 'allalo', 'fundamentals', '101mega', 'pixels', '3optical', '5digital', 'dooms', 'peteynoim', 'timehope', 'alritehave', 'js', 'amx', 'burgundy', 'captaining', 'amrita', 'profile', 'bpo', 'nighters', 'persevered', 'regretted', 'spouse', 'pmt', 'sumthin', '4give', 'shldxxxx', 'thatd', 'scenario', 'spunout', 'wrld', 'pounded', 'broadband', 'processed', 'installation', 'tensed', 'coughing', 'survey', 'warned', 'sprint', 'gower', 'morrow', '420', 'alreadysabarish', 'inpersonation', 'flea', 'nys', 'taj', 'symbol', 'lesser', 'known', 'facts', 'shahjahans', 'wifes', 'shahjahan', 'delivery', 'arises', 'hari', 'okcome', 'webadres', 'geting', 'passport', 'multiply', 'independently', 'showed', 'twins', 'equally', 'uneventful', 'pesky', 'cyclists', 'wereare', 'nalla', 'adi', 'entey', 'nattil', 'kittum', 'hire', 'hitman', 'cps', 'outages', 'conserve', 'jordan', 'voted', 'epi', 'bare', 'bhaskar', 'individual', 'gong', 'kaypoh', 'basketball', 'outdoors', 'interfued', 'listed', 'apology', 'hustle', 'forth', 'harlem', 'workout', 'fats', 'zac', 'hui', 'xin', 'versus', 'edge', 'underdtand', 'itboth', 'upnot', 'muchxxlove', 'locaxx', 'skateboarding', 'thrown', 'winds', 'bandages', 'sky', 'hectic', 'virtual', 'apnt', 'pants', 'waiti', 'go2sri', 'lanka', 'wordnot', 'merely', 'relationshipits', 'wherevr', 'gudnyt', 'plum', 'smacks', '50s', 'alot', 'formatting', 'attracts', 'lancaster', 'neway', 'soc', 'bsn', 'advising', 'lobby', 'showered', 'erything', 'lubly', 'rs5', 'sbut', 'luck2', 'catches', 'specify', 'domain', 'nusstu', 'ohi', 'hahatake', 'bari', 'hudgi', 'yorge', 'pataistha', 'ertini', 'hasbroin', 'august', 'jump', 'hoops', 'lateso', 'morningtake', 'dreamsu', 'meummifyingbye', 'associate', 'rip', 'uterus', 'jacuzzi', 'splwat', 'whr', 'aldrine', 'rakhesh', 'rtm', 'herepls', 'callurgent', 'sources', 'unhappiness', 'necesity', 'witout', 'hwd', 'colleg', 'watll', 'wth', 'functions', 'events', 'espell', 'irritated', '4wrd', 'dearloving', 'wthout', 'takecare', 'univ', 'rajas', 'burrito', 'stitch', 'trouser', 'cheetos', 'names', 'synced', 'shangela', 'againloving', 'poo', 'gloucesterroad', 'uup', 'ouch', 'forgiveness', 'glo', 'yesmum', 'wlcome', 'timi', 'fishrman', 'sack', 'strtd', 'throwin', '1stone', 'moraldont', 'physics', 'arpraveesh', 'delicious', 'salad', 'beers', 'whore', 'flood', 'beads', 'wishlist', 'section', 'nitro', 'comfort', 'luxury', 'sold', 'onionrs', 'petrolrs', 'beerrs', 'armands', 'creative', 'fakemy', 'reffering', 'uif', 'getiing', 'rsi', 'weirdy', 'brownies', 'restrict', 'audrey', 'godnot', 'chikkuk', 'vivek', 'outif', 'greece', 'recorded', 'someday', 'goodmorningmy', 'grandfather', 'expiredso', 'yuou', 'spot', 'bunch', 'lotto', 'auction', 'purchases', 'authorise', '645pm', 'honeydid', 'gimmi', 'gossx', 'painit', 'todaydo', 'ystrdayice', 'chile', 'subletting', 'febapril', 'ammaelife', 'steering', 'anythings', 'sleeps', 'rounderso', 'required', 'truekdo', 'lambu', 'ji', 'cometil', 'batchlor', 'zoom', 'pink', 'pure', 'hearted', 'hisher', 'enemies', 'smiley', 'gail', 'wrongtake', 'worryc', 'l8tr', 'hunlove', 'yaxxx', 'theoretically', 'hooked', 'formallypls', 'prayingwill', 'multimedia', 'senthilhsbc', 'vague', 'accounting', 'delayed', 'housing', 'agency', 'renting', 'presents', 'nicky', 'gumbys', 'sized', 'tarpon', 'springs', 'cab', 'availablethey', 'steps', 'careumma', 'limited', 'deartake', 'radiator', 'proper', 'tongued', 'shorts', 'qi', 'suddenly', 'flurries', 'perform', 'cards', 'rebooting', 'nigh', 'nooooooo', 'cable', 'outage', 'sos', 'playin', 'guoyang', 'rahul', 'dengra', 'antelope', 'toplay', 'fieldof', 'selfindependence', 'contention', 'growrandom', 'borderline', '545', 'nightnight', 'possibility', 'grooved', 'mising', 'lanre', 'fakeyes', 'eckankar', 'ph', 'degrees', 'dodgey', 'seing', 'funky', 'faceasssssholeeee', 'ceri', 'rebel', 'dreamz', 'buddy', 'nationwide', 'newport', 'shortly', 'juliana', 'nachos', 'dizzamn', 'suitemates', 'nimbomsons', 'continent', 'emerging', 'fiendmake', 'muchimpede', 'hesitant', 'ow', 'deyi', '60400thousadi', 'sumthinxx', 'nose', 'essay', 'tram', 'vic', 'coherently', 'gran', 'onlyfound', 'afew', 'agocusoon', 'honi', 'southern', 'rayan', 'macleran', 'balls', 'olave', 'mandara', 'trishul', 'woo', 'hoo', 'panties', 'thout', 'flatter', 'pints', 'carlin', 'ciao', 'starve', 'impression', 'motivate', 'darkness', 'timeyou', 'wknd', 'yalrigu', 'heltiniiyo', 'shared', 'meso', 'uttered', 'trusting', 'meok', 'chikkub', 'noice', 'esaplanade', 'occurs', 'enna', 'kalaachutaarama', 'coco', 'sporadically', 'burden', 'harder', 'nbme', 'sickness', 'gam', 'smash', 'religiously', 'await', 'muhommad', 'penny', 'hubby', 'fiting', 'load', 'hwkeep', 'mj', 'unconvinced', 'elaborate', 'willpower', 'absence', 'answerin', 'evey', 'mnth', 'prin', 'ashwini', 'tomorrowtoday', 'jokethet', 'skinny', 'lineyou', 'casting', 'hockey', 'elections', '116', 'hlday', 'camp', 'amrca', 'serena', 'prescribed', 'med', 'meatballs', 'approve', 'panalambut', 'posts', 'fortune', 'allday', 'perf', 'outsider', 'receiptswell', '98321561', 'familiar', 'depression', 'infact', 'cornwall', 'shite', 'kip', 'hont', 'nannys', 'puts', 'perspective', 'sonot', 'conveying', 'debating', 'jb', 'youso', 'florida', 'hidden', 'teams', 'swhrt', 'deyhope', '2daylove', 'misstake', 'eye', 'general', 'ifwhenhow', 'dayhas', 'valuemorning', 'hopeafternoon', 'faithevening', 'luvnight', 'restwish', 'todaygood', 'jetton', 'friendofafriend', 'dealer', 'lunsford', 'enjoying', 'kfc', 'meals', 'gravy', 'dahe', 'daalways', 'thisdon', 'messagepandy', 'attended', 'mw', 'tuth', 'mines', 'eviction', 'spiral', 'michael', 'riddance', 'suffers', 'raglan', 'edward', 'cricket', 'closeby', 'daplease', 'skye', 'bookedthe', 'hut', 'drastic', 'garments', 'sez', 'arab', 'evry1', 'eshxxxxxxxxxxx', 'lay', 'bimbo', 'ugos', 'detroit', 'portege', 'm100', 'semiobscure', 'loosu', 'careless', 'freaking', 'myspace', 'logged', 'partners', 'method', 'jewelry', 'fumbling', 'stone', 'weekdays', 'nails', 'nobodys', 'asia', 'stil', 'tobed', 'pimples', 'asthma', 'attack', 'ball', 'spin', 'haiyoh', 'million', 'auntys', 'prsn', 'somtimes', 'saves', 'bcozi', 'audiitions', 'relocate', 'pocked', 'motivating', 'sharing', 'brison', 'spelled', 'caps', 'among', 'bullshit', 'gwr', 'motherfucker', 'woodland', 'avenue', 'parish', 'magazine', 'telephone', 'billy', 'awww', 'useless', 'loo', 'helloed', 'swollen', 'glands', 'bcaz', 'stu', '2im', 'truble', 'evone', 'hates', 'view', 'gays', 'games', 'dual', 'hostile', 'haircut', 'breezy', '1appledayno', '1tulsi', 'leafdayno', '1lemondayno', '1cup', 'milkdayno', 'problms', 'litres', 'watrdayno', 'diseases', 'snd', 'lavender', 'manky', 'scouse', 'stevelike', 'travelling', 'homewot', 'inmind', 'recreation', 'judgementali', 'fridays', 'hidid', 'waheeda', 'allow', 'bot', 'notes', 'deary', 'eventually', 'tolerance', 'hits', 'hellogorgeous', 'nitw', 'texd', 'hopeu', '4ward', 'cin', 'jaz', 'exorcism', 'emily', 'evry', 'emotion', 'wordsevry', 'prayrs', 'uothrwise', 'uso', 'ujhhhhhhh', 'sandiago', 'parantella', 'hugging', 'sweater', 'mango', 'involved', 'consent', 'forms', 'mathews', 'tait', 'edwards', 'anderson', 'haunt', 'promoting', 'crowd', 'snowboarding', 'goa', 'christmassy', 'baaaaaaaabe', 'ignoring', 'shola', 'sagamu', 'lautech', 'vital', 'completes', 'education', 'rates', 'zealand', 'qet', 'dial', 'browser', 'surf', 'wellyou', 'lifeyou', 'thati', 'conversations', 'usget', 'timeyour', 'sensesrespect', 'overemphasiseor', 'internal', 'subs', 'extract', 'godyou', 'immed', 'skint', 'fancied', 'bevieswaz', 'othrs', 'spoon', 'watchng', 'planet', 'earthsofa', 'comfey', 'quitting', 'least5times', 'wudnt', 'ima', 'frequently', 'messageit', 'cupboard', 'route', '2mro', 'uk', 'risk', 'grasp', 'flavour', 'laready', 'denying', 'dom', 'ffffuuuuuuu', 'julianaland', 'oblivious', 'upsetits', 'dehydrated', 'mapquest', 'dogwood', 'archive', 'lengths', 'behalf', 'stunning', 'visa', 'gucci', 'shits', 'babesozi', 'culdnt', 'talkbut', 'wannatell', 'wenwecan', 'smsing', 'efficient', '515pm', 'erutupalam', 'thandiyachu', 'invention', 'flyim', 'noits', 'lyrics', 'nevr', 'unrecognized', 'somone', 'valuing', 'definitly', 'undrstnd', 'ger', 'toking', 'syd', 'lehhaha', 'khelate', 'kintu', 'opponenter', 'dhorte', 'lage', 'fried', 'spares', 'looovvve', 'warwick', 'tmw', 'canceled', 'tops', 'grandma', 'parade', 'posting', 'chennaibecause', 'grumble', 'linear', 'algebra', 'decorating', 'roomate', 'graduated', 'adjustable', 'cooperative', 'allows', 'nottingham', '63miles', '40mph', 'mornin', 'thanku', '2morro', 'guessed', 'itxx', 'beside', 'brisk', 'walks', 'steve', 'tellmiss', 'partys', 'contribute', 'greatly', 'urgh', 'coach', 'smells', 'duvet', 'predictive', 'url', '24th', 'sept', 'beverage', 'vpist', 'surrender', 'symptoms', 'rdy', 'comp', 'itnow', 'backwards', 'abstract', 'vikkyim', 'africa', 'avin', 'quiteamuzing', 'thatscool', 'rows', 'engagement', 'fixd', 'bthmm', 'njan', 'vilikkamt', 'sudn', 'maths', 'chapter', 'chop', 'noooooooo', 'firsg', 'split', 'heat', 'applyed', 'laid', 'voucher', 'virgin', 'sumfing', 'hiphop', 'oxygen', 'resort', 'roller', 'sport', 'showr', 'upon', 'ceiling', 'presnts', 'bcz', 'jeevithathile', 'irulinae', 'neekunna', 'prakasamanu', 'sneham', 'prakasam', 'ennal', 'mns', 'islove', 'blowing', 'firmware', 'vijaykanth', 'tvhe', 'hide', 'anythiing', 'keypad', 'btwn', 'decades', 'goverment', 'expects', 'spice', 'prasanth', 'ettans', 'appy', 'fizz', 'contains', 'genus', 'robinson', 'nottel', 'outs', 'soz', 'imat', 'msgsometext', 'wewa', '130', 'iriver', '255', '128', 'bw', 'dajst', 'hmmmbut', 'surly', 'ending', 'capital', 'mmmmmmm', 'snuggles', 'contented', 'whispers', 'error', 'healthy', '2bold', 'givits', 'kanoanyway', 'sticky', 'scraped', 'barrel', 'misfits', 's8', 'sections', 'clearer', 'peach', 'tasts', 'therell', 'shindig', 'phonebook', 'keng', 'rocking', 'ashes', 'xins', 'shijutta', 'kafter', 'offense', 'bbdthts', 'dvg', 'coldheard', 'vinobanagar', 'conditionand', 'ovulatewhen', '3wks', 'woah', 'realising', 'orh', 'hides', 'thousands', 'secrets', 'n8', 'darlinim', 'soonxxx', 'canteen', 'stressfull', 'adds', '140', '180', 'leastwhich', 'bedrm', 'pleasured', 'hitechnical', 'supportproviding', 'assistance', 'watever', 'built', 'lonlines', 'lotz', 'memories', 'gailxx', 'hii', 'repeat', 'instructions', 'complacent', 'mina', 'miwa', 'hsbc', 'statement', 'mth', 'mths', 'opposite', 'heavily', 'dolls', 'patrick', 'swayze', 'quarter', 'flirting', 'nervous', 'fired', 'limping', 'followed', 'aa', 'oga', 'poorly', 'punishment', 'brb', 'kill', 'predicte', 'situations', 'loosing', 'smaller', 'capacity', 'defer', 'admission', 'checkmate', 'chess', 'persian', 'phrase', 'shah', 'maat', 'rats', 'themes', 'pee', 'burns', 'photoshop', 'manageable', 'inshah', 'ashley', 'sthis', 'increase', 'wifedont', 'iti', 'toolets', 'north', 'carolina', 'texas', 'gre', 'bomb', 'breathing', 'powerful', 'weapon', 'lovly', 'playi', 'clas', 'lit', 'loooooool', 'couch', 'swashbuckling', '5terror', '6cruel', '7romantic', '8lovable', '9decent', 'joker', 'dips', 'gek1510', 'cruise', 'feelin', 'happiest', 'characters', 'differences', 'lists', 'tylers', 'crisis', 'whenwhere', 'antibiotic', 'abdomen', 'gynae', '6times', 'exposed', 'chastity', 'device', 'beatings', 'uses', 'gut', 'wrenching', 'tallahassee', 'taka', 'wrote', 'ritten', 'fold', 'solihull', 'nhs', 'mistakeu', 'bornplease', 'local', '2b', 'terminatedwe', 'inconvenience', 'dentists', 'parent', 'itsnot', 'childs', 'parentnot', 'unintentional', 'nonetheless', 'hooch', 'toaday', 'splat', 'grazed', 'confirmdeny', 'hearin', 'yah', 'torture', 'england', 'hopeing', 'sisters', 'lips', 'startedindia', 'kkcongratulation', 'court', 'chapel', 'frontierville', 'mountain', 'deer', 'maili', 'mailed', 'varma', 'membershiptake', 'careinsha', 'secure', 'farting', 'ortxt', 'stuffing', 'ahhhhjust', 'uphad', 'thoso', 'viveki', '96', 'dado', 'kaila', 'hos', 'collapsed', 'cumming', 'jade', 'paul', 'barmed', 'thinkthis', 'dangerous', 'rushing', 'channel', 'coulda', '1230', 'okday', 'hmph', 'baller', 'punto', 'ayo', 'travelled', 'toyota', 'camry', 'olayiwolas', 'mileage', 'kits', 'landing', 'clover', 'numberpls', 'idconvey', 'achanammarakheshqatar', 'rencontre', 'mountains', 'galsu', 'puppy', 'noise', 'crossing', 'inconvenient', 'vldo', 'adsense', 'approved', 'dudette', 'perumbavoor', 'stage', 'clarify', 'preponed', 'younger', 'liver', 'hmmmstill', 'opener', 'guides', 'watched', 'loneliness', 'skyving', 'club', 'onwords', 'mtnl', 'mumbai', 'rajitha', 'ranju', 'styles', 'disagreeable', 'afterwards', 'uawakefeellikw', 'shitjustfound', 'aletter', 'thatmum', 'gotmarried', '4thnovbehind', 'ourbacks', 'fuckinniceselfish', 'rearrange', 'dormitory', 'astronomer', 'starer', 'election', 'recount', 'motherinlaw', 'hitler', 'eleven', 'worms', 'suffering', 'dysentry', 'andre', 'virgils', 'lorgoin', 'gokila', 'shanilrakhesh', 'herethanksi', 'exchanged', 'uncut', 'diamond', 'stuffleaving', 'dino', 'prem', 'kkthis', 'kotees', 'hassling', 'andres', 'haughaighgtujhyguj', 'fassyole', 'blacko', 'londn', 'responsibilities', 'humanities', 'reassurance', 'aslamalaikkuminsha', 'tohar', 'beeen', 'muht', 'albi', 'mufti', 'mahfuuzmeaning', 'enufcredeit', 'tocallshall', 'ileave', 'treats', 'okors', 'ibored', 'adding', 'zeros', 'savings', 'goigng', 'perfume', 'sday', 'joinedso', 'grocers', 'pubs', 'frankie', 'bennys', 'warner', 'changing', 'diapers', 'owed', 'unlike', 'patients', 'turkeys', 'helens', 'princes', 'dawhere', 'unintentionally', 'wenever', 'familymay', 'stability', 'tranquility', 'vibrant', 'colourful', 'renewal', 'bawling', 'failure', 'failing', 'velusamy', 'sirs', 'facilities', 'karnan', 'bluray', 'salt', 'wounds', 'logging', 'geoenvironmental', 'implications', 'gently', 'fuuuuck', 'salmon', 'uploaded', 'wrkin', 'awkward', 'splash', 'leg', 'musta', 'overdid', 'hiwhat', 'downloaded', 'foned', 'chuck', 'nightswe', 'port', 'liaotoo', 'stuffs', 'juswoke', 'boatin', 'docks', 'spinout', 'remet', 'uworld', 'qbank', 'assessment', 'tke', 'temales', 'vidnot', 'finishd', 'dull', 'studies', 'anyones', 'treadmill', 'craigslist', 'absolutely', 'drmstake', 'swan', 'teethif', 'asapok', 'hellohow', 'doingwhat', '2when', 'lamp', 'latebut', 'kwish', 'foward', 'misundrstud', '2u2', 'genes', 'resuming', 'reapply', 'treatin', 'treacle', 'mumhas', 'beendropping', 'theplace', 'adress', 'moneyi', 'oyster', 'sashimi', 'rumbling', 'marandratha', 'topic', 'correctly', 'sirsalam', 'alaikkumpride', 'shopwe', 'qatarrakhesh', 'indianpls', 'numberrespectful', 'galcan', 'boyy', 'galno', 'heaven', 'princegn', 'pisces', 'aquarius', '2yrs', 'steyn', 'wicket', 'sterm', 'resolved', 'jam', 'hannaford', 'wheat', 'chex', 'pride', 'grownup', 'stuffwhy', 'costume', 'jerk', 'stink', 'openings', 'upcharge', '8hr', 'guai', 'select', 'astrology', 'ryans', 'program', 'slacking', 'officestill', 'formsdon', 'mentor', '100', 'percent', 'sane', 'helping', 'spacebucks', 'weathers', 'squeezed', 'meremove', 'maintaining', '5im', 'dreading', 'thou', 'suggestion', 'lands', 'helps', 'forgt', 'ajith', 'ooooooh', 'yoville', 'mega', 'asda', 'counts', 'officer', 'respectful', 'bffs', 'carly', 'someonethat', 'seperatedud', 'brolly', 'franxx', 'welli', 'prometazine', 'syrup', '5mls', 'feed', 'singapore', 'victoria', 'pocay', 'wocay', '2morrowxxxx', 'broth', 'ramen', 'fowler', 'ksry', 'sivatats', 'flew', '1526', 'pubcafe', 'attention', 'tix', 'biolas', 'fne', 'youdoing', 'worc', 'foregate', 'shrub', 'get4an18th', 'shopthe', 'receipts', 'pendent', 'hu', 'navigate', 'choosing', 'require', 'guidance', 'chick', 'boobs', 'revealing', 'gyno', 'belong', 'treasure', 'slide', 'mummys', 'positive', 'negative', 'hmmmm', 'dhoni', 'titleso', 'command', 'stressful', 'holby', 'li', 'lecturer', 'repeating', 'yeovil', 'motor', 'max', 'rhode', 'bong', 'ofcourse', 'upload', 'loti', 'tamilnaduthen', 'tip', 'apo', 'identification', 'limit', 'boundaries', 'endless', 'reassuring', 'lorwe', 'young', 'referin', 'meis', 'liaoso', 'saibaba', 'colany', 'chic', 'declare', 'disappointment', 'irritation', 'tantrums', 'compliments', 'adventuring', 'chief', 'mouse', 'desk', 'childporn', 'jumpers', 'hat', 'belt', 'cribbs', 'spiritual', 'barring', 'sudden', 'influx', 'kane', 'shud', 'pshewmissing', 'units', 'accent', '4years', 'dental', 'nmde', 'dump', 'heap', 'lowes', 'sony', 'salesman', 'pity', 'soany', 'suggestions', 'bitching']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Machine Learning"
      ],
      "metadata": {
        "id": "AGoLg9at2zH-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Resources:\n",
        "\n",
        "https://towardsdatascience.com/text-classification-using-naive-bayes-theory-a-working-example-2ef4b7eb7d5a\n",
        "\n",
        "https://towardsdatascience.com/which-machine-learning-model-to-use-db5fdf37f3dd\n",
        "\n",
        "https://towardsdatascience.com/spam-or-ham-introduction-to-natural-language-processing-part-2-a0093185aebd\n",
        "\n",
        "https://machinelearningmastery.com/prepare-text-data-machine-learning-scikit-learn/\n",
        "\n",
        "https://www.geeksforgeeks.org/multiclass-classification-using-scikit-learn/"
      ],
      "metadata": {
        "id": "htlb7AcJDgrx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Imports"
      ],
      "metadata": {
        "id": "M7_e9ekSDcpI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier"
      ],
      "metadata": {
        "id": "o85bG-tYDbyN"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_and_test_model(model, X, y):\n",
        "  # Split the data into train and test sets.\n",
        "\n",
        "  X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42, test_size=0.1, shuffle=True)\n",
        "\n",
        "  # Reset indexes (Prevents incorrect joins)\n",
        "\n",
        "  X_train = X_train.reset_index().drop(['index'], axis=1)\n",
        "  X_test = X_test.reset_index().drop(['index'], axis=1)\n",
        "  y_train = y_train.reset_index().drop(['index'], axis=1)\n",
        "  y_test = y_test.reset_index().drop(['index'], axis=1)\n",
        "\n",
        "  # If the Text column is included, train and fit the vectorizer using the training set.\n",
        "  if 'Text' in X.columns:\n",
        "    vectorizer = TfidfVectorizer()\n",
        "    encoded = vectorizer.fit_transform(X_train['Text']).toarray()\n",
        "    encoded = pd.DataFrame(encoded)\n",
        "    X_train = X_train.join(encoded)\n",
        "    X_train = X_train.drop(['Text'], axis=1)\n",
        "\n",
        "  model.fit(X_train, y_train)\n",
        "\n",
        "  # If the text column is included, apply the same transformation to test set.\n",
        "  if 'Text' in X.columns:\n",
        "    encoded = vectorizer.transform(X_test['Text']).toarray()\n",
        "    encoded = pd.DataFrame(encoded)\n",
        "    X_test = X_test.join(encoded)\n",
        "    X_test = X_test.drop(['Text'], axis=1)\n",
        "\n",
        "  # Make predictions using the test set, and display the confusion matrix.\n",
        "\n",
        "  y_pred = model.predict(X_test)\n",
        "  print(\"-------\")\n",
        "  print(\"Model:\" + str(model))\n",
        "  print(\"Confusion matrix:\")\n",
        "  print(confusion_matrix(y_test, y_pred))\n",
        "  print(\"Accuracy Score:\")\n",
        "  score = accuracy_score(y_test, y_pred)\n",
        "  print(score)\n",
        "  return score"
      ],
      "metadata": {
        "id": "wzUXtIe3Dj2f"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def compare_models(feature_set_number, X, y):\n",
        "  scores = {}\n",
        "  scores['FeatureSetNumber'] = feature_set_number\n",
        "  scores['SVC'] = train_and_test_model(SVC(random_state = 0), X, y)\n",
        "  scores['GaussianNB'] = train_and_test_model(GaussianNB(), X, y)\n",
        "  scores['DecisionTreeClassifier'] = train_and_test_model(DecisionTreeClassifier(random_state = 0), X, y)\n",
        "  scores['KNeighborsClassifier'] = train_and_test_model(KNeighborsClassifier(), X, y)\n",
        "  return scores\n"
      ],
      "metadata": {
        "id": "qgmCdu3fLAp9"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Our y is consistent across all models. \n",
        "y = pd.DataFrame(df['IsSpam'])"
      ],
      "metadata": {
        "id": "S4MgAmR-GJZu"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Feature Set 1:\n",
        "\n",
        "X = [Text]\n",
        "\n",
        "Y = [IsSpam]"
      ],
      "metadata": {
        "id": "YDK23ET32mi5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = pd.DataFrame(df['Text'])\n",
        "feature_set_1_scores = compare_models(1, X, y)"
      ],
      "metadata": {
        "id": "P7vszBkr2StJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "46f5af20-00a6-40ef-900f-f7248637b9ad"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------\n",
            "Model:SVC(random_state=0)\n",
            "Confusion matrix:\n",
            "[[491   0]\n",
            " [  8  59]]\n",
            "Accuracy Score:\n",
            "0.985663082437276\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------\n",
            "Model:GaussianNB()\n",
            "Confusion matrix:\n",
            "[[438  53]\n",
            " [  3  64]]\n",
            "Accuracy Score:\n",
            "0.899641577060932\n",
            "-------\n",
            "Model:DecisionTreeClassifier(random_state=0)\n",
            "Confusion matrix:\n",
            "[[487   4]\n",
            " [ 11  56]]\n",
            "Accuracy Score:\n",
            "0.9731182795698925\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/neighbors/_classification.py:198: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  return self._fit(X, y)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------\n",
            "Model:KNeighborsClassifier()\n",
            "Confusion matrix:\n",
            "[[491   0]\n",
            " [ 36  31]]\n",
            "Accuracy Score:\n",
            "0.9354838709677419\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Feature Set 2:\n",
        "\n",
        "X = [Text, WordCount, TypoCount, Sentiment, LexicalDiversity]\n",
        "\n",
        "Y = [IsSpam]"
      ],
      "metadata": {
        "id": "VT7IM14xeUoz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = df.drop(['IsSpam'], axis=1)\n",
        "feature_set_2_scores = compare_models(2, X, y)"
      ],
      "metadata": {
        "id": "Yn0UdWfveZau",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5500f0fe-07eb-4782-fe15-5be086f49b21"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/utils/validation.py:1688: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['int', 'str']. An error will be raised in 1.2.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/utils/validation.py:1688: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['int', 'str']. An error will be raised in 1.2.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------\n",
            "Model:SVC(random_state=0)\n",
            "Confusion matrix:\n",
            "[[477  14]\n",
            " [ 37  30]]\n",
            "Accuracy Score:\n",
            "0.9086021505376344\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/utils/validation.py:1688: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['int', 'str']. An error will be raised in 1.2.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/utils/validation.py:1688: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['int', 'str']. An error will be raised in 1.2.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------\n",
            "Model:GaussianNB()\n",
            "Confusion matrix:\n",
            "[[438  53]\n",
            " [  3  64]]\n",
            "Accuracy Score:\n",
            "0.899641577060932\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/utils/validation.py:1688: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['int', 'str']. An error will be raised in 1.2.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/utils/validation.py:1688: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['int', 'str']. An error will be raised in 1.2.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------\n",
            "Model:DecisionTreeClassifier(random_state=0)\n",
            "Confusion matrix:\n",
            "[[482   9]\n",
            " [  9  58]]\n",
            "Accuracy Score:\n",
            "0.967741935483871\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/utils/validation.py:1688: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['int', 'str']. An error will be raised in 1.2.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/neighbors/_classification.py:198: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  return self._fit(X, y)\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/utils/validation.py:1688: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['int', 'str']. An error will be raised in 1.2.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------\n",
            "Model:KNeighborsClassifier()\n",
            "Confusion matrix:\n",
            "[[468  23]\n",
            " [ 28  39]]\n",
            "Accuracy Score:\n",
            "0.9086021505376344\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Feature Set 3:\n",
        "X = [Text, WordCount, TypoCount, Sentiment]\n",
        "\n",
        "Y = [IsSpam]"
      ],
      "metadata": {
        "id": "R9aBHkhV1jwI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = df.drop(['IsSpam', 'LexicalDiversity'], axis=1)\n",
        "feature_set_3_scores = compare_models(3, X, y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8yg0ybZw1J1I",
        "outputId": "40ee0783-5bf4-4912-974e-99792ce551b2"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/utils/validation.py:1688: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['int', 'str']. An error will be raised in 1.2.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/utils/validation.py:1688: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['int', 'str']. An error will be raised in 1.2.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------\n",
            "Model:SVC(random_state=0)\n",
            "Confusion matrix:\n",
            "[[477  14]\n",
            " [ 37  30]]\n",
            "Accuracy Score:\n",
            "0.9086021505376344\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/utils/validation.py:1688: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['int', 'str']. An error will be raised in 1.2.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/utils/validation.py:1688: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['int', 'str']. An error will be raised in 1.2.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------\n",
            "Model:GaussianNB()\n",
            "Confusion matrix:\n",
            "[[438  53]\n",
            " [  3  64]]\n",
            "Accuracy Score:\n",
            "0.899641577060932\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/utils/validation.py:1688: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['int', 'str']. An error will be raised in 1.2.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/utils/validation.py:1688: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['int', 'str']. An error will be raised in 1.2.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------\n",
            "Model:DecisionTreeClassifier(random_state=0)\n",
            "Confusion matrix:\n",
            "[[484   7]\n",
            " [  8  59]]\n",
            "Accuracy Score:\n",
            "0.9731182795698925\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/utils/validation.py:1688: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['int', 'str']. An error will be raised in 1.2.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/neighbors/_classification.py:198: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  return self._fit(X, y)\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/utils/validation.py:1688: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['int', 'str']. An error will be raised in 1.2.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------\n",
            "Model:KNeighborsClassifier()\n",
            "Confusion matrix:\n",
            "[[471  20]\n",
            " [ 28  39]]\n",
            "Accuracy Score:\n",
            "0.9139784946236559\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Feature Set 4:\n",
        "\n",
        "X = [WordCount, TypoCount, Sentiment, LexicalDiversity]\n",
        "\n",
        "Y = [IsSpam]"
      ],
      "metadata": {
        "id": "ZWemloWHGLQU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = df.drop(['Text', 'IsSpam'], axis=1)\n",
        "feature_set_4_scores = compare_models(4, X, y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ljfh2zYqzi13",
        "outputId": "a15c57bb-b226-4785-bf6f-1460c4a63f44"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------\n",
            "Model:SVC(random_state=0)\n",
            "Confusion matrix:\n",
            "[[476  15]\n",
            " [ 39  28]]\n",
            "Accuracy Score:\n",
            "0.9032258064516129\n",
            "-------\n",
            "Model:GaussianNB()\n",
            "Confusion matrix:\n",
            "[[468  23]\n",
            " [ 30  37]]\n",
            "Accuracy Score:\n",
            "0.9050179211469535\n",
            "-------\n",
            "Model:DecisionTreeClassifier(random_state=0)\n",
            "Confusion matrix:\n",
            "[[466  25]\n",
            " [ 29  38]]\n",
            "Accuracy Score:\n",
            "0.9032258064516129\n",
            "-------\n",
            "Model:KNeighborsClassifier()\n",
            "Confusion matrix:\n",
            "[[466  25]\n",
            " [ 33  34]]\n",
            "Accuracy Score:\n",
            "0.8960573476702509\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/neighbors/_classification.py:198: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  return self._fit(X, y)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Feature Set 5:\n",
        "X = [WordCount, TypoCount, Sentiment]\n",
        "\n",
        "Y = [IsSpam]"
      ],
      "metadata": {
        "id": "8hxxUS7K1V9z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = df.drop(['Text', 'IsSpam', 'LexicalDiversity'], axis = 1)\n",
        "feature_set_5_scores = compare_models(5, X, y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "idqKv3TL0oYu",
        "outputId": "a3acf517-d547-40a8-c0a5-67e06ebefcf1"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------\n",
            "Model:SVC(random_state=0)\n",
            "Confusion matrix:\n",
            "[[477  14]\n",
            " [ 39  28]]\n",
            "Accuracy Score:\n",
            "0.9050179211469535\n",
            "-------\n",
            "Model:GaussianNB()\n",
            "Confusion matrix:\n",
            "[[469  22]\n",
            " [ 37  30]]\n",
            "Accuracy Score:\n",
            "0.8942652329749103\n",
            "-------\n",
            "Model:DecisionTreeClassifier(random_state=0)\n",
            "Confusion matrix:\n",
            "[[462  29]\n",
            " [ 25  42]]\n",
            "Accuracy Score:\n",
            "0.9032258064516129\n",
            "-------\n",
            "Model:KNeighborsClassifier()\n",
            "Confusion matrix:\n",
            "[[467  24]\n",
            " [ 34  33]]\n",
            "Accuracy Score:\n",
            "0.8960573476702509\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/neighbors/_classification.py:198: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  return self._fit(X, y)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5. Results and Discussion:"
      ],
      "metadata": {
        "id": "8mQDwDVPQSvP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Lexical Analysis:"
      ],
      "metadata": {
        "id": "PUADOkBLo6kG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "spam_word_count = df.loc[df['IsSpam'] == True, 'WordCount'].sum()\n",
        "ham_word_count = df.loc[df['IsSpam'] == False, 'WordCount'].sum()\n",
        "\n",
        "spam_average_word_count = (spam_word_count / df.loc[df['IsSpam'] == True].shape[0])\n",
        "ham_average_word_count = (ham_word_count / df.loc[df['IsSpam'] == False].shape[0])\n",
        "\n",
        "print(\"Spam average word count:\", spam_average_word_count)\n",
        "print(\"Ham average word count:\", ham_average_word_count)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U4B3iLzKRShI",
        "outputId": "ff8460ce-5fc6-4e4d-de6d-c5342a33afe2"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Spam average word count: 23.564926372155288\n",
            "Ham average word count: 13.975129533678757\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "spam_typo_count = df.loc[df['IsSpam'] == True, 'TypoCount'].sum()\n",
        "ham_typo_count = df.loc[df['IsSpam'] == False, 'TypoCount'].sum()\n",
        "\n",
        "spam_word_count = df.loc[df['IsSpam'] == True, 'WordCount'].sum()\n",
        "ham_word_count = df.loc[df['IsSpam'] == False, 'WordCount'].sum()\n",
        "\n",
        "spam_percentage_of_words_with_typos = (spam_typo_count / spam_word_count) * 100\n",
        "ham_percentage_of_words_with_typos = (ham_typo_count / ham_word_count) * 100\n",
        "\n",
        "\n",
        "print(\"Spam total typos: \", spam_typo_count)\n",
        "print(\"Ham total typos: \", ham_typo_count)\n",
        "print(\"Percentage of spam words with typos:\", spam_percentage_of_words_with_typos, \"%\")\n",
        "print(\"Percentage of ham words with typos:\", ham_percentage_of_words_with_typos, \"%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OXZPrxrVRW_k",
        "outputId": "c16151c2-e7bc-4625-aeaf-eb95732b405d"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Spam total typos:  3705\n",
            "Ham total typos:  8459\n",
            "Percentage of spam words with typos: 21.047548713287508 %\n",
            "Percentage of ham words with typos: 12.544861337683525 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "spam_df = df.loc[df['IsSpam'] == True]\n",
        "ham_df = df.loc[df['IsSpam'] == False]\n",
        "\n",
        "spam_average_sentiment = spam_df['Sentiment'].sum() / len(spam_df)\n",
        "ham_average_sentiment = ham_df['Sentiment'].sum() / len(ham_df)\n",
        "\n",
        "print(\"Spam Sentiment: \", spam_average_sentiment)\n",
        "print(\"Ham Sentiment: \", ham_average_sentiment)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "izKGtzAORgQm",
        "outputId": "1583e72d-6614-4fa1-c1b0-309f8973d165"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Spam Sentiment:  0.440570281124498\n",
            "Ham Sentiment:  0.15124992746113988\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "spam_df = df.loc[df['IsSpam'] == True]\n",
        "ham_df = df.loc[df['IsSpam'] == False]\n",
        "\n",
        "spam_diversity = spam_df['LexicalDiversity'].sum() / len(spam_df)\n",
        "ham_diversity = ham_df['LexicalDiversity'].sum() / len(ham_df)\n",
        "\n",
        "print(\"Spam Average Lexical Diversity: \", spam_diversity)\n",
        "print(\"Ham Average Lexical Diversity: \", ham_diversity)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yfMishwHRkuD",
        "outputId": "a3f65ff7-2a6d-41dc-f7ed-4e46e566e2fe"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Spam Average Lexical Diversity:  0.9365141684121667\n",
            "Ham Average Lexical Diversity:  0.9508276026592045\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ham_freq_str = str(spam_freq_dist.most_common(10))\n",
        "\n",
        "def pretty_print_freq_dist(freq_dist):\n",
        "  freq_str = str(freq_dist.most_common(10))\n",
        "  freq_str = freq_str.replace('[', '')\n",
        "  freq_str = freq_str.replace(']', '')\n",
        "  return freq_str\n",
        "\n",
        "summary_data = {\"Label\": [\"Spam\", \"Ham\"], \n",
        "                \"AverageWordCount\": [spam_average_word_count, ham_average_word_count], \n",
        "                \"PercentageOfWordsWithTypos\": [spam_percentage_of_words_with_typos, ham_percentage_of_words_with_typos],\n",
        "                \"AverageSentiment\": [spam_average_sentiment, ham_average_sentiment],\n",
        "                \"AverageLexicalDiversity\": [spam_diversity, ham_diversity],\n",
        "                \"MostCommonWords\": [pretty_print_freq_dist(spam_freq_dist), pretty_print_freq_dist(ham_freq_dist)]}\n",
        "\n",
        "summary_df = pd.DataFrame(summary_data)\n",
        "display(summary_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 103
        },
        "id": "PSA127pmQVCn",
        "outputId": "0b7c1e47-baa0-493c-ed31-b61a9f0af4e9"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  Label  AverageWordCount  PercentageOfWordsWithTypos  AverageSentiment  \\\n",
              "0  Spam         23.564926                   21.047549           0.44057   \n",
              "1   Ham         13.975130                   12.544861           0.15125   \n",
              "\n",
              "   AverageLexicalDiversity                                    MostCommonWords  \n",
              "0                 0.936514  ('call', 347), ('free', 216), ('2', 173), ('tx...  \n",
              "1                 0.950828  ('u', 972), ('im', 458), ('2', 305), ('get', 3...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a3c7dc22-28e0-4a8a-b082-2858ad2d93e6\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Label</th>\n",
              "      <th>AverageWordCount</th>\n",
              "      <th>PercentageOfWordsWithTypos</th>\n",
              "      <th>AverageSentiment</th>\n",
              "      <th>AverageLexicalDiversity</th>\n",
              "      <th>MostCommonWords</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Spam</td>\n",
              "      <td>23.564926</td>\n",
              "      <td>21.047549</td>\n",
              "      <td>0.44057</td>\n",
              "      <td>0.936514</td>\n",
              "      <td>('call', 347), ('free', 216), ('2', 173), ('tx...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Ham</td>\n",
              "      <td>13.975130</td>\n",
              "      <td>12.544861</td>\n",
              "      <td>0.15125</td>\n",
              "      <td>0.950828</td>\n",
              "      <td>('u', 972), ('im', 458), ('2', 305), ('get', 3...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a3c7dc22-28e0-4a8a-b082-2858ad2d93e6')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-a3c7dc22-28e0-4a8a-b082-2858ad2d93e6 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-a3c7dc22-28e0-4a8a-b082-2858ad2d93e6');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "#### Average Word Count: \n",
        "We can see that spam texts tend to be much longer than ham messages. ~10.59 words more on average. This makes sense since spam messages need to contain enough information to convince the recipient to complete a call to action. \n",
        "\n",
        "####Percentage of words with typos:\n",
        "We can see that spam messages also tend to contain much more typos than ham messages. ~8.5% more words with typos on average. This was in line with expectations, as spam messages are often poorly written.\n",
        "\n",
        "#### Average Sentiment:\n",
        "We can see that spam messages tend to have a stronger positive sentiment on average. I was surprised by this outcome. I expected the average sentiment to be closer to 0, as many spam messages can be threatening.\n",
        "\n",
        "#### Average Lexical Diversity:\n",
        "We can see no significant difference between spam and ham messages. I was surprised by this, as I expected spam messages to have lower lexical diversity than ham messages. I realise that because text messages tend to be very short, there is a much higher probability that all words in the message are unique. This explains the very high lexical diversity in both spam and ham messages.\n",
        "\n",
        "#### Most Common Words:\n",
        "\n",
        "We can see a common trend in spam messages. Spam messages tend to contain a call to action. We can see that 6 out of the 10 most common words relate to a call to action: “call”, “free”, “txt”, “mobile”, “text”, and “claim”. Spam top 10 common words only overlap the ham top 10 common words with “u”, “2”, and “ur”. \n"
      ],
      "metadata": {
        "id": "hp-w1soSob_D"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Machine Learning:"
      ],
      "metadata": {
        "id": "ruvEi61Kp27f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "summary_machine_learning = [feature_set_1_scores, feature_set_2_scores, feature_set_3_scores, feature_set_4_scores, feature_set_5_scores]\n",
        "summary_machine_learning_df = pd.DataFrame(summary_machine_learning)\n",
        "summary_machine_learning_df['AverageScore'] = (summary_machine_learning_df.drop(['FeatureSetNumber'], axis = 1).sum(axis = 1)) / (len(feature_set_1_scores) - 1)\n",
        "display(summary_machine_learning_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "id": "qrwmTr5bRCCD",
        "outputId": "bb8013bd-d8d2-4907-a2ca-1520ae7ee391"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "   FeatureSetNumber       SVC  GaussianNB  DecisionTreeClassifier  \\\n",
              "0                 1  0.985663    0.899642                0.973118   \n",
              "1                 2  0.908602    0.899642                0.967742   \n",
              "2                 3  0.908602    0.899642                0.973118   \n",
              "3                 4  0.903226    0.905018                0.903226   \n",
              "4                 5  0.905018    0.894265                0.903226   \n",
              "\n",
              "   KNeighborsClassifier  AverageScore  \n",
              "0              0.935484      0.948477  \n",
              "1              0.908602      0.921147  \n",
              "2              0.913978      0.923835  \n",
              "3              0.896057      0.901882  \n",
              "4              0.896057      0.899642  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-5018fc36-72a0-4d64-aa94-c39611e7b751\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>FeatureSetNumber</th>\n",
              "      <th>SVC</th>\n",
              "      <th>GaussianNB</th>\n",
              "      <th>DecisionTreeClassifier</th>\n",
              "      <th>KNeighborsClassifier</th>\n",
              "      <th>AverageScore</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>0.985663</td>\n",
              "      <td>0.899642</td>\n",
              "      <td>0.973118</td>\n",
              "      <td>0.935484</td>\n",
              "      <td>0.948477</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>0.908602</td>\n",
              "      <td>0.899642</td>\n",
              "      <td>0.967742</td>\n",
              "      <td>0.908602</td>\n",
              "      <td>0.921147</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>0.908602</td>\n",
              "      <td>0.899642</td>\n",
              "      <td>0.973118</td>\n",
              "      <td>0.913978</td>\n",
              "      <td>0.923835</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>0.903226</td>\n",
              "      <td>0.905018</td>\n",
              "      <td>0.903226</td>\n",
              "      <td>0.896057</td>\n",
              "      <td>0.901882</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>0.905018</td>\n",
              "      <td>0.894265</td>\n",
              "      <td>0.903226</td>\n",
              "      <td>0.896057</td>\n",
              "      <td>0.899642</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5018fc36-72a0-4d64-aa94-c39611e7b751')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-5018fc36-72a0-4d64-aa94-c39611e7b751 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-5018fc36-72a0-4d64-aa94-c39611e7b751');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The above table compares accuracy scores for different combinations of feature sets and machine learning models. \n",
        "\n",
        "From our results, we can see that Feature Set 1 was the most accurate on average, with an average accuracy score of 0.948. This was expected as our model was being trained directly on the text content. Our least accurate feature set was Feature Set 5, with an average accuracy of 0.899. \n",
        "\n",
        "We can see no significant difference between Feature Set 2 and Feature Set 3 (0.002688%). We also see virtually no difference between Feature Set 4 and Feature Set 5 (0.00224%). This shows that including or excluding lexical diversity had no real effect on the outcome of the dataset. \n",
        "\n",
        "I was surprised that Feature Set 2 and Feature Set 3 had a lower accuracy score than Feature Set 1. I expected that including the lexical data along with the text data would help the model distinguish between the two datasets. \n",
        "\n",
        "Our most successful feature set/model combination was Feature Set 1 + SVC, with an accuracy score of 0.985.  Our least successful feature set/model combination was Feature Set 5 + GaussianNB, with an accuracy score of 0.894. \n",
        "\n",
        "Our results show that we can use the lexical features alone can be used to make relatively accurate predictions on whether a message is spam or ham. (~90% accurate).\n"
      ],
      "metadata": {
        "id": "PdR9vXDppz9f"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 6: Reflection:"
      ],
      "metadata": {
        "id": "U8gJMkGhqQau"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "While we achieved good results with our data, this project had several limitations.\n",
        "\n",
        "One limitation was due to the size of the messages. Since text messages are so short, we cannot effectively compare lexical diversity. Both the spam dataset and the ham dataset had lexical diversity scores close to 1 as a result.\n",
        "\n",
        "Another limitation was the relatively small dataset. While the total number of ham messages was adequate (4825 total), there was only a small number of spam messages (747 total). We would likely achieve higher accuracy scores with a larger number of spam data to train on. \n",
        "\n",
        "Another limitation is how we calculate typos. Our method considers a token to contain typos when the token isn’t contained in the WordNet set or the English Stopwords Set. This means that common slang such as ‘lol’ would be counted as a typo used when they are widely used and understood. This also means that other acronyms would also be counted as typos. If I were to continue this project, I would include a set of common text acronyms as an additional set to check each token against.\n",
        "\n",
        "Another limitation is the age of the data. The UCI SMS Spam Collection Data Set was donated on 22-06-2012. The underlying data is likely much older than this. Because older phones didn't include auto-completion, we would expect acronyms to be more common during older text messages. Using our method of calculating typo percentages, we would expect newer text messages to have fewer typos than old messages. This may make it more difficult for our model to predict whether newer text messages are spam or ham. \n",
        "\n",
        "Finally, our machine learning models were all used with default parameters. We would likely achieve greater results with parameter optimisation, for example through a grid search. Since optimising parameters is time-consuming and computationally expensive, it was outside the scope of this project. \n"
      ],
      "metadata": {
        "id": "0LEntm0hqTLB"
      }
    }
  ]
}